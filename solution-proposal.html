<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Solution proposal | A Technical Companion for BAN443</title>
  <meta name="description" content="BAN443: A brief course on transforming business with AI through Large Language Models. Learn Python programming, LLM fundamentals, API integration, LangChain framework, and practical applications for data analysis, automation, and business transformation." />
  <meta name="generator" content="bookdown 0.44 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Solution proposal | A Technical Companion for BAN443" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="BAN443: A brief course on transforming business with AI through Large Language Models. Learn Python programming, LLM fundamentals, API integration, LangChain framework, and practical applications for data analysis, automation, and business transformation." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Solution proposal | A Technical Companion for BAN443" />
  
  <meta name="twitter:description" content="BAN443: A brief course on transforming business with AI through Large Language Models. Learn Python programming, LLM fundamentals, API integration, LangChain framework, and practical applications for data analysis, automation, and business transformation." />
  

<meta name="author" content="Eirik Berger Abel" />


<meta name="date" content="2025-10-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="exercises.html"/>
<link rel="next" href="final-words.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6KCKS5548F"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-6KCKS5548F');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">BAN443: Transforming Business with AI</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome to BAN443</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#course-schedule"><i class="fa fa-check"></i><b>1.1</b> Course Schedule</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#compulsory-activity"><i class="fa fa-check"></i><b>1.2</b> Compulsory Activity</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#assessment"><i class="fa fa-check"></i><b>1.3</b> Assessment</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#course-overview"><i class="fa fa-check"></i><b>1.4</b> Course Overview</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#getting-started"><i class="fa fa-check"></i><b>1.5</b> Getting Started</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#contact-and-support"><i class="fa fa-check"></i><b>1.6</b> Contact and Support</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction to Python</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#why-python-for-ai"><i class="fa fa-check"></i><b>2.1</b> Why Python for AI?</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#setting-up-your-environment"><i class="fa fa-check"></i><b>2.2</b> Setting Up Your Environment</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="intro.html"><a href="intro.html#option-1-google-colab-recommended-for-beginners"><i class="fa fa-check"></i><b>2.2.1</b> Option 1: Google Colab (Recommended for Beginners)</a></li>
<li class="chapter" data-level="2.2.2" data-path="intro.html"><a href="intro.html#option-2-local-installation"><i class="fa fa-check"></i><b>2.2.2</b> Option 2: Local Installation</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#essential-python-concepts"><i class="fa fa-check"></i><b>2.3</b> Essential Python Concepts</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="intro.html"><a href="intro.html#variables-and-data-types"><i class="fa fa-check"></i><b>2.3.1</b> Variables and Data Types</a></li>
<li class="chapter" data-level="2.3.2" data-path="intro.html"><a href="intro.html#functions"><i class="fa fa-check"></i><b>2.3.2</b> Functions</a></li>
<li class="chapter" data-level="2.3.3" data-path="intro.html"><a href="intro.html#installing-and-importing-packages"><i class="fa fa-check"></i><b>2.3.3</b> Installing and Importing Packages</a></li>
<li class="chapter" data-level="2.3.4" data-path="intro.html"><a href="intro.html#working-with-data"><i class="fa fa-check"></i><b>2.3.4</b> Working with Data</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#working-with-apis"><i class="fa fa-check"></i><b>2.4</b> Working with APIs</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="intro.html"><a href="intro.html#what-is-an-api"><i class="fa fa-check"></i><b>2.4.1</b> What is an API?</a></li>
<li class="chapter" data-level="2.4.2" data-path="intro.html"><a href="intro.html#example-of-using-api-to-get-got-quotes"><i class="fa fa-check"></i><b>2.4.2</b> Example of using API to get GoT quotes</a></li>
<li class="chapter" data-level="2.4.3" data-path="intro.html"><a href="intro.html#working-with-json-objects"><i class="fa fa-check"></i><b>2.4.3</b> Working with JSON Objects</a></li>
<li class="chapter" data-level="2.4.4" data-path="intro.html"><a href="intro.html#api-authentication"><i class="fa fa-check"></i><b>2.4.4</b> API Authentication</a></li>
<li class="chapter" data-level="2.4.5" data-path="intro.html"><a href="intro.html#google-drive-integration"><i class="fa fa-check"></i><b>2.4.5</b> Google Drive Integration</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#want-to-learn-more"><i class="fa fa-check"></i><b>2.5</b> Want to learn more?</a></li>
<li class="chapter" data-level="2.6" data-path="intro.html"><a href="intro.html#next-steps"><i class="fa fa-check"></i><b>2.6</b> Next Steps</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="llm-fundamentals.html"><a href="llm-fundamentals.html"><i class="fa fa-check"></i><b>3</b> Understanding Large Language Models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="llm-fundamentals.html"><a href="llm-fundamentals.html#what-are-large-language-models"><i class="fa fa-check"></i><b>3.1</b> What Are Large Language Models?</a></li>
<li class="chapter" data-level="3.2" data-path="llm-fundamentals.html"><a href="llm-fundamentals.html#neural-networks-the-foundation"><i class="fa fa-check"></i><b>3.2</b> Neural Networks: The Foundation</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="llm-fundamentals.html"><a href="llm-fundamentals.html#what-is-a-neural-network"><i class="fa fa-check"></i><b>3.2.1</b> What is a Neural Network?</a></li>
<li class="chapter" data-level="3.2.2" data-path="llm-fundamentals.html"><a href="llm-fundamentals.html#how-information-flows"><i class="fa fa-check"></i><b>3.2.2</b> How Information Flows</a></li>
<li class="chapter" data-level="3.2.3" data-path="llm-fundamentals.html"><a href="llm-fundamentals.html#neural-networks-vs.-traditional-regression"><i class="fa fa-check"></i><b>3.2.3</b> Neural Networks vs. Traditional Regression</a></li>
<li class="chapter" data-level="3.2.4" data-path="llm-fundamentals.html"><a href="llm-fundamentals.html#how-neural-networks-learn"><i class="fa fa-check"></i><b>3.2.4</b> How Neural Networks Learn</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="llm-fundamentals.html"><a href="llm-fundamentals.html#from-neural-networks-to-language-models"><i class="fa fa-check"></i><b>3.3</b> From Neural Networks to Language Models</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="llm-fundamentals.html"><a href="llm-fundamentals.html#the-language-modeling-task"><i class="fa fa-check"></i><b>3.3.1</b> The Language Modeling Task</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="llm-fundamentals.html"><a href="llm-fundamentals.html#how-language-models-work"><i class="fa fa-check"></i><b>3.4</b> How Language Models Work</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="llm-fundamentals.html"><a href="llm-fundamentals.html#tokenization-from-text-to-numbers"><i class="fa fa-check"></i><b>3.4.1</b> Tokenization: From Text to Numbers</a></li>
<li class="chapter" data-level="3.4.2" data-path="llm-fundamentals.html"><a href="llm-fundamentals.html#training-large-language-models"><i class="fa fa-check"></i><b>3.4.2</b> Training Large Language Models</a></li>
<li class="chapter" data-level="3.4.3" data-path="llm-fundamentals.html"><a href="llm-fundamentals.html#next-token-prediction-the-core-of-llms"><i class="fa fa-check"></i><b>3.4.3</b> Next Token Prediction: The Core of LLMs</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="llm-fundamentals.html"><a href="llm-fundamentals.html#want-to-learn-more-1"><i class="fa fa-check"></i><b>3.5</b> Want to learn more?</a></li>
<li class="chapter" data-level="3.6" data-path="llm-fundamentals.html"><a href="llm-fundamentals.html#next-steps-1"><i class="fa fa-check"></i><b>3.6</b> Next Steps</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html"><i class="fa fa-check"></i><b>4</b> Working with LLMs through APIs</a>
<ul>
<li class="chapter" data-level="4.1" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#using-the-openai-packages"><i class="fa fa-check"></i><b>4.1</b> Using the OpenAI Packages</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#installation"><i class="fa fa-check"></i><b>4.1.1</b> Installation</a></li>
<li class="chapter" data-level="4.1.2" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#essential-package-imports"><i class="fa fa-check"></i><b>4.1.2</b> Essential Package Imports</a></li>
<li class="chapter" data-level="4.1.3" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#api-configuration"><i class="fa fa-check"></i><b>4.1.3</b> API Configuration</a></li>
<li class="chapter" data-level="4.1.4" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#basic-chat-completion"><i class="fa fa-check"></i><b>4.1.4</b> Basic Chat Completion</a></li>
<li class="chapter" data-level="4.1.5" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#message-object-structure"><i class="fa fa-check"></i><b>4.1.5</b> Message Object Structure</a></li>
<li class="chapter" data-level="4.1.6" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#structured-data-extraction"><i class="fa fa-check"></i><b>4.1.6</b> Structured Data Extraction</a></li>
<li class="chapter" data-level="4.1.7" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#creating-reusable-functions"><i class="fa fa-check"></i><b>4.1.7</b> Creating Reusable Functions</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#using-langchain"><i class="fa fa-check"></i><b>4.2</b> Using LangChain</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#installation-1"><i class="fa fa-check"></i><b>4.2.1</b> Installation</a></li>
<li class="chapter" data-level="4.2.2" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#api-configuration-1"><i class="fa fa-check"></i><b>4.2.2</b> API Configuration</a></li>
<li class="chapter" data-level="4.2.3" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#basic-chat-completion-and-message-structure"><i class="fa fa-check"></i><b>4.2.3</b> Basic Chat Completion and Message Structure</a></li>
<li class="chapter" data-level="4.2.4" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#structured-data-extraction-1"><i class="fa fa-check"></i><b>4.2.4</b> Structured Data Extraction</a></li>
<li class="chapter" data-level="4.2.5" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#prompt-templates"><i class="fa fa-check"></i><b>4.2.5</b> Prompt Templates</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#using-langsmith-to-track-your-llm-usage"><i class="fa fa-check"></i><b>4.3</b> Using LangSmith to track your LLM usage</a></li>
<li class="chapter" data-level="4.4" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#using-langgraph-to-build-more-advanced-llm-applications"><i class="fa fa-check"></i><b>4.4</b> Using LangGraph to build more advanced LLM applications</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#building-chatbots-with-langgraph"><i class="fa fa-check"></i><b>4.4.1</b> Building Chatbots with LangGraph</a></li>
<li class="chapter" data-level="4.4.2" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#simple-chatbot-without-memory"><i class="fa fa-check"></i><b>4.4.2</b> Simple Chatbot (Without Memory)</a></li>
<li class="chapter" data-level="4.4.3" data-path="working-with-llms-through-apis.html"><a href="working-with-llms-through-apis.html#advanced-chatbot-with-memory"><i class="fa fa-check"></i><b>4.4.3</b> Advanced Chatbot (With Memory)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>5</b> Applications</a>
<ul>
<li class="chapter" data-level="5.1" data-path="applications.html"><a href="applications.html#data-extraction-from-the-norwegian-national-library"><i class="fa fa-check"></i><b>5.1</b> Data Extraction from the Norwegian National Library</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="applications.html"><a href="applications.html#setting-up-langchain-with-azure-openai"><i class="fa fa-check"></i><b>5.1.1</b> Setting up LangChain with Azure OpenAI</a></li>
<li class="chapter" data-level="5.1.2" data-path="applications.html"><a href="applications.html#structured-data-extraction-2"><i class="fa fa-check"></i><b>5.1.2</b> Structured Data Extraction</a></li>
<li class="chapter" data-level="5.1.3" data-path="applications.html"><a href="applications.html#fetching-data-from-the-norwegian-national-library"><i class="fa fa-check"></i><b>5.1.3</b> Fetching Data from the Norwegian National Library</a></li>
<li class="chapter" data-level="5.1.4" data-path="applications.html"><a href="applications.html#batch-processing-with-caching"><i class="fa fa-check"></i><b>5.1.4</b> Batch Processing with Caching</a></li>
<li class="chapter" data-level="5.1.5" data-path="applications.html"><a href="applications.html#converting-json-results-to-dataframe"><i class="fa fa-check"></i><b>5.1.5</b> Converting JSON Results to DataFrame</a></li>
<li class="chapter" data-level="5.1.6" data-path="applications.html"><a href="applications.html#analyzing-occupation-data"><i class="fa fa-check"></i><b>5.1.6</b> Analyzing Occupation Data</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="applications.html"><a href="applications.html#web-search-and-tools-integration"><i class="fa fa-check"></i><b>5.2</b> Web Search and Tools Integration</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="applications.html"><a href="applications.html#basic-web-search-with-tavily"><i class="fa fa-check"></i><b>5.2.1</b> Basic Web Search with Tavily</a></li>
<li class="chapter" data-level="5.2.2" data-path="applications.html"><a href="applications.html#agent-with-web-search-capabilities"><i class="fa fa-check"></i><b>5.2.2</b> Agent with Web Search Capabilities</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="applications.html"><a href="applications.html#retrieval-augmented-generation-rag-systems"><i class="fa fa-check"></i><b>5.3</b> Retrieval-Augmented Generation (RAG) Systems</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="applications.html"><a href="applications.html#basic-rag-implementation"><i class="fa fa-check"></i><b>5.3.1</b> Basic RAG Implementation</a></li>
<li class="chapter" data-level="5.3.2" data-path="applications.html"><a href="applications.html#persistent-vector-database"><i class="fa fa-check"></i><b>5.3.2</b> Persistent Vector Database</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="applications.html"><a href="applications.html#company-data-extraction-from-brønnøysundregisteret"><i class="fa fa-check"></i><b>5.4</b> Company Data Extraction from Brønnøysundregisteret</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="additional-content.html"><a href="additional-content.html"><i class="fa fa-check"></i><b>6</b> Additional Content</a>
<ul>
<li class="chapter" data-level="6.1" data-path="additional-content.html"><a href="additional-content.html#open-source-models"><i class="fa fa-check"></i><b>6.1</b> Open Source models</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="additional-content.html"><a href="additional-content.html#why-choose-open-source-models"><i class="fa fa-check"></i><b>6.1.1</b> Why Choose Open Source Models?</a></li>
<li class="chapter" data-level="6.1.2" data-path="additional-content.html"><a href="additional-content.html#downsides-and-challenges"><i class="fa fa-check"></i><b>6.1.2</b> Downsides and Challenges</a></li>
<li class="chapter" data-level="6.1.3" data-path="additional-content.html"><a href="additional-content.html#where-to-get-open-source-models-hugging-face"><i class="fa fa-check"></i><b>6.1.3</b> Where to Get Open Source Models: Hugging Face</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="additional-content.html"><a href="additional-content.html#overview-of-models-and-their-capabilities"><i class="fa fa-check"></i><b>6.2</b> Overview of Models and Their Capabilities</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="additional-content.html"><a href="additional-content.html#measuring-model-quality"><i class="fa fa-check"></i><b>6.2.1</b> Measuring Model Quality</a></li>
<li class="chapter" data-level="6.2.2" data-path="additional-content.html"><a href="additional-content.html#model-comparison-resources"><i class="fa fa-check"></i><b>6.2.2</b> Model Comparison Resources</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="additional-content.html"><a href="additional-content.html#risks-of-llms-and-ai"><i class="fa fa-check"></i><b>6.3</b> Risks of LLMs and AI</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>7</b> Exercises</a>
<ul>
<li class="chapter" data-level="7.1" data-path="exercises.html"><a href="exercises.html#lab-1"><i class="fa fa-check"></i><b>7.1</b> Lab 1</a></li>
<li class="chapter" data-level="7.2" data-path="exercises.html"><a href="exercises.html#lab-2"><i class="fa fa-check"></i><b>7.2</b> Lab 2</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="solution-proposal.html"><a href="solution-proposal.html"><i class="fa fa-check"></i><b>8</b> Solution proposal</a>
<ul>
<li class="chapter" data-level="8.1" data-path="solution-proposal.html"><a href="solution-proposal.html#lab-1-1"><i class="fa fa-check"></i><b>8.1</b> Lab 1</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="solution-proposal.html"><a href="solution-proposal.html#question-1-using-an-api-and-making-a-function-from-it"><i class="fa fa-check"></i><b>8.1.1</b> Question 1: Using an API and making a function from it</a></li>
<li class="chapter" data-level="8.1.2" data-path="solution-proposal.html"><a href="solution-proposal.html#question-2-making-a-chatbot-for-this-course"><i class="fa fa-check"></i><b>8.1.2</b> Question 2: Making a chatbot for this course</a></li>
<li class="chapter" data-level="8.1.3" data-path="solution-proposal.html"><a href="solution-proposal.html#question-3-analyze-letterboxd-dataset"><i class="fa fa-check"></i><b>8.1.3</b> Question 3: Analyze Letterboxd dataset</a></li>
<li class="chapter" data-level="8.1.4" data-path="solution-proposal.html"><a href="solution-proposal.html#question-4"><i class="fa fa-check"></i><b>8.1.4</b> Question 4</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="solution-proposal.html"><a href="solution-proposal.html#lab-2-1"><i class="fa fa-check"></i><b>8.2</b> Lab 2</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="solution-proposal.html"><a href="solution-proposal.html#question-1-journalist-llm"><i class="fa fa-check"></i><b>8.2.1</b> Question 1: Journalist LLM</a></li>
<li class="chapter" data-level="8.2.2" data-path="solution-proposal.html"><a href="solution-proposal.html#question-2-dataset-analysis"><i class="fa fa-check"></i><b>8.2.2</b> Question 2: Dataset Analysis</a></li>
<li class="chapter" data-level="8.2.3" data-path="solution-proposal.html"><a href="solution-proposal.html#question-3-chatbot-with-additional-information"><i class="fa fa-check"></i><b>8.2.3</b> Question 3: Chatbot with Additional Information</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>9</b> Final Words</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Technical Companion for BAN443</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="solution-proposal" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Solution proposal<a href="solution-proposal.html#solution-proposal" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="lab-1-1" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Lab 1<a href="solution-proposal.html#lab-1-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><a href="https://colab.research.google.com/drive/1w9h1BA0Gt263cT3cGtxAFCOjLUnxQPft?usp=sharing" target="_blank">
<img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a></p>
<div id="question-1-using-an-api-and-making-a-function-from-it" class="section level3 hasAnchor" number="8.1.1">
<h3><span class="header-section-number">8.1.1</span> Question 1: Using an API and making a function from it<a href="solution-proposal.html#question-1-using-an-api-and-making-a-function-from-it" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This question contains two parts: 1) Making an API work and 2) ‘wrapping’ it inside a function.</p>
<p>Let’s start with number 1. We can make our life easy and choose an API that is “public”, meaning it doesn’t require an API key or we can choose something interesting that does require an API key. I will do both.</p>
<div id="api-function-without-api-key" class="section level4 hasAnchor" number="8.1.1.1">
<h4><span class="header-section-number">8.1.1.1</span> API function without API key<a href="solution-proposal.html#api-function-without-api-key" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb64"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="solution-proposal.html#cb64-1" aria-hidden="true"></a><span class="im">import</span> requests</span>
<span id="cb64-2"><a href="solution-proposal.html#cb64-2" aria-hidden="true"></a></span>
<span id="cb64-3"><a href="solution-proposal.html#cb64-3" aria-hidden="true"></a><span class="kw">def</span> get_got_quotes(character: <span class="bu">str</span>):</span>
<span id="cb64-4"><a href="solution-proposal.html#cb64-4" aria-hidden="true"></a>    base_url <span class="op">=</span> <span class="st">&quot;https://api.gameofthronesquotes.xyz/v1&quot;</span></span>
<span id="cb64-5"><a href="solution-proposal.html#cb64-5" aria-hidden="true"></a>    <span class="cf">try</span>:</span>
<span id="cb64-6"><a href="solution-proposal.html#cb64-6" aria-hidden="true"></a>        response <span class="op">=</span> requests.get(<span class="ss">f&quot;</span><span class="sc">{</span>base_url<span class="sc">}</span><span class="ss">/author/</span><span class="sc">{</span>character<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb64-7"><a href="solution-proposal.html#cb64-7" aria-hidden="true"></a>        data <span class="op">=</span> response.json()</span>
<span id="cb64-8"><a href="solution-proposal.html#cb64-8" aria-hidden="true"></a>        data <span class="op">=</span> data[<span class="st">&#39;sentence&#39;</span>] <span class="co"># Note this line of code. We typically don&#39;t want to return the full response from the API. Here, we just want the sentence.</span></span>
<span id="cb64-9"><a href="solution-proposal.html#cb64-9" aria-hidden="true"></a>        <span class="cf">return</span> data</span>
<span id="cb64-10"><a href="solution-proposal.html#cb64-10" aria-hidden="true"></a>    <span class="cf">except</span> response:</span>
<span id="cb64-11"><a href="solution-proposal.html#cb64-11" aria-hidden="true"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Error: </span><span class="sc">{</span>response<span class="sc">.</span>status_code<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb64-12"><a href="solution-proposal.html#cb64-12" aria-hidden="true"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb64-13"><a href="solution-proposal.html#cb64-13" aria-hidden="true"></a></span>
<span id="cb64-14"><a href="solution-proposal.html#cb64-14" aria-hidden="true"></a><span class="co"># Example usage</span></span>
<span id="cb64-15"><a href="solution-proposal.html#cb64-15" aria-hidden="true"></a>get_got_quotes(<span class="st">&quot;tyrion&quot;</span>)</span></code></pre></div>
</div>
<div id="api-function-with-api-key" class="section level4 hasAnchor" number="8.1.1.2">
<h4><span class="header-section-number">8.1.1.2</span> API function with API key<a href="solution-proposal.html#api-function-with-api-key" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="solution-proposal.html#cb65-1" aria-hidden="true"></a><span class="im">import</span> requests</span>
<span id="cb65-2"><a href="solution-proposal.html#cb65-2" aria-hidden="true"></a><span class="im">from</span> google.colab <span class="im">import</span> userdata</span>
<span id="cb65-3"><a href="solution-proposal.html#cb65-3" aria-hidden="true"></a></span>
<span id="cb65-4"><a href="solution-proposal.html#cb65-4" aria-hidden="true"></a><span class="kw">def</span> get_stock_data(symbol: <span class="bu">str</span>, interval: <span class="bu">str</span> <span class="op">=</span> <span class="st">&quot;5min&quot;</span>):</span>
<span id="cb65-5"><a href="solution-proposal.html#cb65-5" aria-hidden="true"></a>    <span class="co">&quot;&quot;&quot;Fetch intraday stock data from Alpha Vantage.&quot;&quot;&quot;</span></span>
<span id="cb65-6"><a href="solution-proposal.html#cb65-6" aria-hidden="true"></a>    api_key <span class="op">=</span> userdata.get(<span class="st">&quot;alphavantage_key&quot;</span>)</span>
<span id="cb65-7"><a href="solution-proposal.html#cb65-7" aria-hidden="true"></a>    url <span class="op">=</span> (</span>
<span id="cb65-8"><a href="solution-proposal.html#cb65-8" aria-hidden="true"></a>        <span class="ss">f&quot;https://www.alphavantage.co/query?&quot;</span></span>
<span id="cb65-9"><a href="solution-proposal.html#cb65-9" aria-hidden="true"></a>        <span class="ss">f&quot;function=TIME_SERIES_INTRADAY&amp;symbol=</span><span class="sc">{</span>symbol<span class="sc">}</span><span class="ss">&amp;interval=</span><span class="sc">{</span>interval<span class="sc">}</span><span class="ss">&amp;apikey=</span><span class="sc">{</span>api_key<span class="sc">}</span><span class="ss">&quot;</span>  <span class="co"># This is one way to include the api key (see documentation for your specific API)</span></span>
<span id="cb65-10"><a href="solution-proposal.html#cb65-10" aria-hidden="true"></a>    )</span>
<span id="cb65-11"><a href="solution-proposal.html#cb65-11" aria-hidden="true"></a>    response <span class="op">=</span> requests.get(url)</span>
<span id="cb65-12"><a href="solution-proposal.html#cb65-12" aria-hidden="true"></a>    <span class="cf">return</span> response.json()</span>
<span id="cb65-13"><a href="solution-proposal.html#cb65-13" aria-hidden="true"></a></span>
<span id="cb65-14"><a href="solution-proposal.html#cb65-14" aria-hidden="true"></a><span class="co"># Example usage</span></span>
<span id="cb65-15"><a href="solution-proposal.html#cb65-15" aria-hidden="true"></a>data <span class="op">=</span> get_stock_data(<span class="st">&quot;IBM&quot;</span>)</span>
<span id="cb65-16"><a href="solution-proposal.html#cb65-16" aria-hidden="true"></a><span class="bu">print</span>(data)</span></code></pre></div>
<p>Let’s plot the data:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="solution-proposal.html#cb66-1" aria-hidden="true"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb66-2"><a href="solution-proposal.html#cb66-2" aria-hidden="true"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb66-3"><a href="solution-proposal.html#cb66-3" aria-hidden="true"></a></span>
<span id="cb66-4"><a href="solution-proposal.html#cb66-4" aria-hidden="true"></a><span class="co"># Note that this function does not contain a return statement, as it doesn&#39;t return anything. It just</span></span>
<span id="cb66-5"><a href="solution-proposal.html#cb66-5" aria-hidden="true"></a><span class="co"># prints the figure.</span></span>
<span id="cb66-6"><a href="solution-proposal.html#cb66-6" aria-hidden="true"></a><span class="kw">def</span> plot_stock_time_series(data):</span>
<span id="cb66-7"><a href="solution-proposal.html#cb66-7" aria-hidden="true"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb66-8"><a href="solution-proposal.html#cb66-8" aria-hidden="true"></a><span class="co">    Plot the closing price from Alpha Vantage intraday data.</span></span>
<span id="cb66-9"><a href="solution-proposal.html#cb66-9" aria-hidden="true"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb66-10"><a href="solution-proposal.html#cb66-10" aria-hidden="true"></a>    ts <span class="op">=</span> data[<span class="st">&quot;Time Series (5min)&quot;</span>]</span>
<span id="cb66-11"><a href="solution-proposal.html#cb66-11" aria-hidden="true"></a></span>
<span id="cb66-12"><a href="solution-proposal.html#cb66-12" aria-hidden="true"></a>    <span class="co"># Convert to DataFrame</span></span>
<span id="cb66-13"><a href="solution-proposal.html#cb66-13" aria-hidden="true"></a>    df <span class="op">=</span> pd.DataFrame(ts).T  <span class="co"># transpose</span></span>
<span id="cb66-14"><a href="solution-proposal.html#cb66-14" aria-hidden="true"></a>    df.index <span class="op">=</span> pd.to_datetime(df.index)  <span class="co"># timestamps</span></span>
<span id="cb66-15"><a href="solution-proposal.html#cb66-15" aria-hidden="true"></a>    df <span class="op">=</span> df.sort_index()  <span class="co"># chronological order</span></span>
<span id="cb66-16"><a href="solution-proposal.html#cb66-16" aria-hidden="true"></a>    df <span class="op">=</span> df.astype(<span class="bu">float</span>)  <span class="co"># convert strings to numbers</span></span>
<span id="cb66-17"><a href="solution-proposal.html#cb66-17" aria-hidden="true"></a></span>
<span id="cb66-18"><a href="solution-proposal.html#cb66-18" aria-hidden="true"></a>    <span class="co"># Plot</span></span>
<span id="cb66-19"><a href="solution-proposal.html#cb66-19" aria-hidden="true"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb66-20"><a href="solution-proposal.html#cb66-20" aria-hidden="true"></a>    plt.plot(df.index, df[<span class="st">&quot;4. close&quot;</span>], marker<span class="op">=</span><span class="st">&quot;o&quot;</span>, linestyle<span class="op">=</span><span class="st">&quot;-&quot;</span>, label<span class="op">=</span><span class="st">&quot;Close Price&quot;</span>)</span>
<span id="cb66-21"><a href="solution-proposal.html#cb66-21" aria-hidden="true"></a>    plt.title(<span class="st">&quot;Stock Closing Price Over Time&quot;</span>)</span>
<span id="cb66-22"><a href="solution-proposal.html#cb66-22" aria-hidden="true"></a>    plt.xlabel(<span class="st">&quot;Time&quot;</span>)</span>
<span id="cb66-23"><a href="solution-proposal.html#cb66-23" aria-hidden="true"></a>    plt.ylabel(<span class="st">&quot;Price (USD)&quot;</span>)</span>
<span id="cb66-24"><a href="solution-proposal.html#cb66-24" aria-hidden="true"></a>    plt.legend()</span>
<span id="cb66-25"><a href="solution-proposal.html#cb66-25" aria-hidden="true"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb66-26"><a href="solution-proposal.html#cb66-26" aria-hidden="true"></a>    plt.show()</span>
<span id="cb66-27"><a href="solution-proposal.html#cb66-27" aria-hidden="true"></a></span>
<span id="cb66-28"><a href="solution-proposal.html#cb66-28" aria-hidden="true"></a><span class="co"># Example code</span></span>
<span id="cb66-29"><a href="solution-proposal.html#cb66-29" aria-hidden="true"></a>data <span class="op">=</span> get_stock_data(<span class="st">&quot;IBM&quot;</span>)</span>
<span id="cb66-30"><a href="solution-proposal.html#cb66-30" aria-hidden="true"></a>test <span class="op">=</span> plot_stock_time_series(data)</span></code></pre></div>
</div>
</div>
<div id="question-2-making-a-chatbot-for-this-course" class="section level3 hasAnchor" number="8.1.2">
<h3><span class="header-section-number">8.1.2</span> Question 2: Making a chatbot for this course<a href="solution-proposal.html#question-2-making-a-chatbot-for-this-course" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This question asks us to create a chatbot (an LLM) and wants us to make it useful for this course. This entails giving it some knowledge about the course. There are three basic ways to do this:</p>
<ol style="list-style-type: decimal">
<li>Include information about the course in the prompt itself (for example the system prompt)</li>
<li>Allow the LLM to search for information in some database (searching the web, using Retrieval-Augmented Generation (RAG) or similar)</li>
<li>Fine-tuning the model to include information about the course.</li>
</ol>
<p>The last proposal is more complex. The second proposal will be covered in a later notebook/the course website. The easiest solution, which I expect from you in this question, is simply to include the information in the prompt.</p>
<p>Let’s find the code for an input-output chatbot using either LangChain or the OpenAI package and copy it in, change it a bit and show that it works.</p>
<div id="system-prompt" class="section level4 hasAnchor" number="8.1.2.1">
<h4><span class="header-section-number">8.1.2.1</span> System prompt<a href="solution-proposal.html#system-prompt" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="solution-proposal.html#cb67-1" aria-hidden="true"></a>system_prompt <span class="op">=</span> <span class="st">&quot;&quot;&quot;</span></span>
<span id="cb67-2"><a href="solution-proposal.html#cb67-2" aria-hidden="true"></a><span class="st">You are a helpful assistant providing assistance in a master course called BAN443.</span></span>
<span id="cb67-3"><a href="solution-proposal.html#cb67-3" aria-hidden="true"></a></span>
<span id="cb67-4"><a href="solution-proposal.html#cb67-4" aria-hidden="true"></a><span class="st">From the course website:</span></span>
<span id="cb67-5"><a href="solution-proposal.html#cb67-5" aria-hidden="true"></a></span>
<span id="cb67-6"><a href="solution-proposal.html#cb67-6" aria-hidden="true"></a><span class="st">This course aims to provide a comprehensive overview of how recent developments within AI and large language models (LLMs) will transform the business landscape, research, and the labor market. The course will explore the capabilities and limitations of LLMs, ethical considerations, data analysis techniques, and the integration of AI technology into various workflows. The course is designed to equip students with a critical understanding of how LLMs transform business and research, a critical understanding of their costs and benefits, as well as the practical skills to employ LLMs for productive tasks, including big data analysis.</span></span>
<span id="cb67-7"><a href="solution-proposal.html#cb67-7" aria-hidden="true"></a></span>
<span id="cb67-8"><a href="solution-proposal.html#cb67-8" aria-hidden="true"></a><span class="st">Students who take the course might also be interested in taking BAN432 Applied Textual Data Analysis For Business And Finance (NB: BAN432 is not offered autumn 2025).</span></span>
<span id="cb67-9"><a href="solution-proposal.html#cb67-9" aria-hidden="true"></a></span>
<span id="cb67-10"><a href="solution-proposal.html#cb67-10" aria-hidden="true"></a><span class="st">Course responsible</span></span>
<span id="cb67-11"><a href="solution-proposal.html#cb67-11" aria-hidden="true"></a><span class="st">Professor Ingar Haaland, Department of Economics (main course responsible)</span></span>
<span id="cb67-12"><a href="solution-proposal.html#cb67-12" aria-hidden="true"></a></span>
<span id="cb67-13"><a href="solution-proposal.html#cb67-13" aria-hidden="true"></a><span class="st">Ph.D. Eirik Berger Abel, Statistics Norway</span></span>
<span id="cb67-14"><a href="solution-proposal.html#cb67-14" aria-hidden="true"></a></span>
<span id="cb67-15"><a href="solution-proposal.html#cb67-15" aria-hidden="true"></a><span class="st">Learning outcome</span></span>
<span id="cb67-16"><a href="solution-proposal.html#cb67-16" aria-hidden="true"></a><span class="st">Knowledge</span></span>
<span id="cb67-17"><a href="solution-proposal.html#cb67-17" aria-hidden="true"></a></span>
<span id="cb67-18"><a href="solution-proposal.html#cb67-18" aria-hidden="true"></a><span class="st">Upon completion of the course, the student can:</span></span>
<span id="cb67-19"><a href="solution-proposal.html#cb67-19" aria-hidden="true"></a></span>
<span id="cb67-20"><a href="solution-proposal.html#cb67-20" aria-hidden="true"></a><span class="st">Explain the foundational concepts of AI and LLMs, including an overview of the current landscape of models, covering both text models like ChatGPT and others.</span></span>
<span id="cb67-21"><a href="solution-proposal.html#cb67-21" aria-hidden="true"></a><span class="st">Identify applications and implications of AI in business and research.</span></span>
<span id="cb67-22"><a href="solution-proposal.html#cb67-22" aria-hidden="true"></a><span class="st">Recognize the ethical considerations, privacy concerns, and risks associated with AI technology.</span></span>
<span id="cb67-23"><a href="solution-proposal.html#cb67-23" aria-hidden="true"></a><span class="st">Skills</span></span>
<span id="cb67-24"><a href="solution-proposal.html#cb67-24" aria-hidden="true"></a></span>
<span id="cb67-25"><a href="solution-proposal.html#cb67-25" aria-hidden="true"></a><span class="st">Upon completion of the course, the student can:</span></span>
<span id="cb67-26"><a href="solution-proposal.html#cb67-26" aria-hidden="true"></a></span>
<span id="cb67-27"><a href="solution-proposal.html#cb67-27" aria-hidden="true"></a><span class="st">Design and execute effective prompts for interacting with LLMs.</span></span>
<span id="cb67-28"><a href="solution-proposal.html#cb67-28" aria-hidden="true"></a><span class="st">Automate the use of large language models through APIs for productive purposes.</span></span>
<span id="cb67-29"><a href="solution-proposal.html#cb67-29" aria-hidden="true"></a><span class="st">Analyze large text datasets and derive insightful conclusions, leveraging modern techniques to uncover themes and trends.</span></span>
<span id="cb67-30"><a href="solution-proposal.html#cb67-30" aria-hidden="true"></a><span class="st">Evaluate the quality of an AI model for a given purpose.</span></span>
<span id="cb67-31"><a href="solution-proposal.html#cb67-31" aria-hidden="true"></a><span class="st">General Competence</span></span>
<span id="cb67-32"><a href="solution-proposal.html#cb67-32" aria-hidden="true"></a></span>
<span id="cb67-33"><a href="solution-proposal.html#cb67-33" aria-hidden="true"></a><span class="st">Upon completion of the course, the student can:</span></span>
<span id="cb67-34"><a href="solution-proposal.html#cb67-34" aria-hidden="true"></a></span>
<span id="cb67-35"><a href="solution-proposal.html#cb67-35" aria-hidden="true"></a><span class="st">Assess the impact of AI on the labor market and organizational productivity, including a nuanced understanding of AI&#39;s strengths and weaknesses.</span></span>
<span id="cb67-36"><a href="solution-proposal.html#cb67-36" aria-hidden="true"></a><span class="st">Develop and present comprehensive research projects that demonstrate practical applications of AI for big data analysis.</span></span>
<span id="cb67-37"><a href="solution-proposal.html#cb67-37" aria-hidden="true"></a><span class="st">Engage in informed discussions about the future directions of AI technology, its societal implications, potential risks, and other ethical considerations.</span></span>
<span id="cb67-38"><a href="solution-proposal.html#cb67-38" aria-hidden="true"></a><span class="st">&quot;&quot;&quot;</span></span></code></pre></div>
</div>
<div id="azure-openai" class="section level4 hasAnchor" number="8.1.2.2">
<h4><span class="header-section-number">8.1.2.2</span> Azure OpenAI<a href="solution-proposal.html#azure-openai" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb68"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="solution-proposal.html#cb68-1" aria-hidden="true"></a><span class="im">from</span> openai <span class="im">import</span> AzureOpenAI</span>
<span id="cb68-2"><a href="solution-proposal.html#cb68-2" aria-hidden="true"></a><span class="im">from</span> google.colab <span class="im">import</span> userdata</span>
<span id="cb68-3"><a href="solution-proposal.html#cb68-3" aria-hidden="true"></a></span>
<span id="cb68-4"><a href="solution-proposal.html#cb68-4" aria-hidden="true"></a>client <span class="op">=</span> AzureOpenAI(</span>
<span id="cb68-5"><a href="solution-proposal.html#cb68-5" aria-hidden="true"></a>    api_key<span class="op">=</span>userdata.get(<span class="st">&#39;AZURE_OPENAI_API_KEY&#39;</span>),</span>
<span id="cb68-6"><a href="solution-proposal.html#cb68-6" aria-hidden="true"></a>    api_version<span class="op">=</span><span class="st">&quot;2025-01-01-preview&quot;</span>,</span>
<span id="cb68-7"><a href="solution-proposal.html#cb68-7" aria-hidden="true"></a>    base_url<span class="op">=</span><span class="st">&quot;https://gpt-ban443-1.openai.azure.com/openai/deployments/Group01/&quot;</span></span>
<span id="cb68-8"><a href="solution-proposal.html#cb68-8" aria-hidden="true"></a>)</span>
<span id="cb68-9"><a href="solution-proposal.html#cb68-9" aria-hidden="true"></a></span>
<span id="cb68-10"><a href="solution-proposal.html#cb68-10" aria-hidden="true"></a><span class="co"># Simple chat completion</span></span>
<span id="cb68-11"><a href="solution-proposal.html#cb68-11" aria-hidden="true"></a>response <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb68-12"><a href="solution-proposal.html#cb68-12" aria-hidden="true"></a>    model<span class="op">=</span><span class="st">&quot;Group01&quot;</span>,</span>
<span id="cb68-13"><a href="solution-proposal.html#cb68-13" aria-hidden="true"></a>    messages<span class="op">=</span>[</span>
<span id="cb68-14"><a href="solution-proposal.html#cb68-14" aria-hidden="true"></a>        {<span class="st">&quot;role&quot;</span>: <span class="st">&quot;system&quot;</span>, <span class="st">&quot;content&quot;</span>: system_prompt},</span>
<span id="cb68-15"><a href="solution-proposal.html#cb68-15" aria-hidden="true"></a>        {<span class="st">&quot;role&quot;</span>: <span class="st">&quot;user&quot;</span>, <span class="st">&quot;content&quot;</span>: <span class="st">&quot;Who are lecturing in the course BAN443?&quot;</span>}</span>
<span id="cb68-16"><a href="solution-proposal.html#cb68-16" aria-hidden="true"></a>    ],</span>
<span id="cb68-17"><a href="solution-proposal.html#cb68-17" aria-hidden="true"></a>    temperature<span class="op">=</span><span class="dv">0</span></span>
<span id="cb68-18"><a href="solution-proposal.html#cb68-18" aria-hidden="true"></a>)</span>
<span id="cb68-19"><a href="solution-proposal.html#cb68-19" aria-hidden="true"></a></span>
<span id="cb68-20"><a href="solution-proposal.html#cb68-20" aria-hidden="true"></a><span class="bu">print</span>(response.choices[<span class="dv">0</span>].message.content)</span></code></pre></div>
<p>Finally, let us build it in a function to make it easier to use:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="solution-proposal.html#cb69-1" aria-hidden="true"></a><span class="im">from</span> openai <span class="im">import</span> AzureOpenAI</span>
<span id="cb69-2"><a href="solution-proposal.html#cb69-2" aria-hidden="true"></a><span class="im">from</span> google.colab <span class="im">import</span> userdata</span>
<span id="cb69-3"><a href="solution-proposal.html#cb69-3" aria-hidden="true"></a></span>
<span id="cb69-4"><a href="solution-proposal.html#cb69-4" aria-hidden="true"></a><span class="co"># Initialize the client once</span></span>
<span id="cb69-5"><a href="solution-proposal.html#cb69-5" aria-hidden="true"></a>client <span class="op">=</span> AzureOpenAI(</span>
<span id="cb69-6"><a href="solution-proposal.html#cb69-6" aria-hidden="true"></a>    api_key<span class="op">=</span>userdata.get(<span class="st">&quot;AZURE_OPENAI_API_KEY&quot;</span>),</span>
<span id="cb69-7"><a href="solution-proposal.html#cb69-7" aria-hidden="true"></a>    api_version<span class="op">=</span><span class="st">&quot;2025-01-01-preview&quot;</span>,</span>
<span id="cb69-8"><a href="solution-proposal.html#cb69-8" aria-hidden="true"></a>    base_url<span class="op">=</span><span class="st">&quot;https://gpt-ban443-1.openai.azure.com/openai/deployments/Group01/&quot;</span></span>
<span id="cb69-9"><a href="solution-proposal.html#cb69-9" aria-hidden="true"></a>)</span>
<span id="cb69-10"><a href="solution-proposal.html#cb69-10" aria-hidden="true"></a></span>
<span id="cb69-11"><a href="solution-proposal.html#cb69-11" aria-hidden="true"></a><span class="kw">def</span> ask_group01(system_prompt: <span class="bu">str</span>, user_prompt: <span class="bu">str</span>, temperature: <span class="bu">float</span> <span class="op">=</span> <span class="dv">0</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb69-12"><a href="solution-proposal.html#cb69-12" aria-hidden="true"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb69-13"><a href="solution-proposal.html#cb69-13" aria-hidden="true"></a><span class="co">    Send a chat completion request to the Group01 deployment on Azure OpenAI.</span></span>
<span id="cb69-14"><a href="solution-proposal.html#cb69-14" aria-hidden="true"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb69-15"><a href="solution-proposal.html#cb69-15" aria-hidden="true"></a>    response <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb69-16"><a href="solution-proposal.html#cb69-16" aria-hidden="true"></a>        model<span class="op">=</span><span class="st">&quot;Group01&quot;</span>,</span>
<span id="cb69-17"><a href="solution-proposal.html#cb69-17" aria-hidden="true"></a>        messages<span class="op">=</span>[</span>
<span id="cb69-18"><a href="solution-proposal.html#cb69-18" aria-hidden="true"></a>            {<span class="st">&quot;role&quot;</span>: <span class="st">&quot;system&quot;</span>, <span class="st">&quot;content&quot;</span>: system_prompt},</span>
<span id="cb69-19"><a href="solution-proposal.html#cb69-19" aria-hidden="true"></a>            {<span class="st">&quot;role&quot;</span>: <span class="st">&quot;user&quot;</span>, <span class="st">&quot;content&quot;</span>: user_prompt}</span>
<span id="cb69-20"><a href="solution-proposal.html#cb69-20" aria-hidden="true"></a>        ],</span>
<span id="cb69-21"><a href="solution-proposal.html#cb69-21" aria-hidden="true"></a>        temperature<span class="op">=</span>temperature</span>
<span id="cb69-22"><a href="solution-proposal.html#cb69-22" aria-hidden="true"></a>    )</span>
<span id="cb69-23"><a href="solution-proposal.html#cb69-23" aria-hidden="true"></a>    <span class="cf">return</span> response.choices[<span class="dv">0</span>].message.content</span>
<span id="cb69-24"><a href="solution-proposal.html#cb69-24" aria-hidden="true"></a></span>
<span id="cb69-25"><a href="solution-proposal.html#cb69-25" aria-hidden="true"></a><span class="co"># Example use:</span></span>
<span id="cb69-26"><a href="solution-proposal.html#cb69-26" aria-hidden="true"></a>reply <span class="op">=</span> ask_group01(system_prompt, <span class="st">&quot;Who are lecturing in the course BAN443?&quot;</span>)</span>
<span id="cb69-27"><a href="solution-proposal.html#cb69-27" aria-hidden="true"></a><span class="bu">print</span>(reply)</span></code></pre></div>
</div>
<div id="langchain" class="section level4 hasAnchor" number="8.1.2.3">
<h4><span class="header-section-number">8.1.2.3</span> LangChain<a href="solution-proposal.html#langchain" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="solution-proposal.html#cb70-1" aria-hidden="true"></a><span class="co"># Load necessary packages</span></span>
<span id="cb70-2"><a href="solution-proposal.html#cb70-2" aria-hidden="true"></a><span class="im">from</span> google.colab <span class="im">import</span> userdata</span>
<span id="cb70-3"><a href="solution-proposal.html#cb70-3" aria-hidden="true"></a><span class="im">from</span> langchain_openai <span class="im">import</span> AzureChatOpenAI</span>
<span id="cb70-4"><a href="solution-proposal.html#cb70-4" aria-hidden="true"></a><span class="im">from</span> langchain_core.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb70-5"><a href="solution-proposal.html#cb70-5" aria-hidden="true"></a></span>
<span id="cb70-6"><a href="solution-proposal.html#cb70-6" aria-hidden="true"></a><span class="co"># Initiate the llm client</span></span>
<span id="cb70-7"><a href="solution-proposal.html#cb70-7" aria-hidden="true"></a>client <span class="op">=</span> AzureChatOpenAI(</span>
<span id="cb70-8"><a href="solution-proposal.html#cb70-8" aria-hidden="true"></a>    api_key<span class="op">=</span>userdata.get(<span class="st">&quot;AZURE_OPENAI_API_KEY&quot;</span>),</span>
<span id="cb70-9"><a href="solution-proposal.html#cb70-9" aria-hidden="true"></a>    azure_endpoint<span class="op">=</span><span class="st">&quot;https://gpt-ban443-1.openai.azure.com/&quot;</span>,</span>
<span id="cb70-10"><a href="solution-proposal.html#cb70-10" aria-hidden="true"></a>    api_version<span class="op">=</span><span class="st">&quot;2025-01-01-preview&quot;</span>,</span>
<span id="cb70-11"><a href="solution-proposal.html#cb70-11" aria-hidden="true"></a>    azure_deployment<span class="op">=</span><span class="st">&quot;Group01&quot;</span>,</span>
<span id="cb70-12"><a href="solution-proposal.html#cb70-12" aria-hidden="true"></a>    temperature<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb70-13"><a href="solution-proposal.html#cb70-13" aria-hidden="true"></a>)</span>
<span id="cb70-14"><a href="solution-proposal.html#cb70-14" aria-hidden="true"></a></span>
<span id="cb70-15"><a href="solution-proposal.html#cb70-15" aria-hidden="true"></a><span class="co"># Define the message object</span></span>
<span id="cb70-16"><a href="solution-proposal.html#cb70-16" aria-hidden="true"></a>messages <span class="op">=</span> [</span>
<span id="cb70-17"><a href="solution-proposal.html#cb70-17" aria-hidden="true"></a>    (<span class="st">&quot;system&quot;</span>, system_prompt),</span>
<span id="cb70-18"><a href="solution-proposal.html#cb70-18" aria-hidden="true"></a>    (<span class="st">&quot;human&quot;</span>, <span class="st">&quot;Who are lecturing in the course BAN443?&quot;</span>),</span>
<span id="cb70-19"><a href="solution-proposal.html#cb70-19" aria-hidden="true"></a>]</span>
<span id="cb70-20"><a href="solution-proposal.html#cb70-20" aria-hidden="true"></a></span>
<span id="cb70-21"><a href="solution-proposal.html#cb70-21" aria-hidden="true"></a>ai_msg <span class="op">=</span> client.invoke(messages)</span>
<span id="cb70-22"><a href="solution-proposal.html#cb70-22" aria-hidden="true"></a><span class="bu">print</span>(ai_msg.content)</span></code></pre></div>
<p>Then, we wrap this in a function as with the OpenAI Azure package:</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="solution-proposal.html#cb71-1" aria-hidden="true"></a><span class="im">from</span> google.colab <span class="im">import</span> userdata</span>
<span id="cb71-2"><a href="solution-proposal.html#cb71-2" aria-hidden="true"></a><span class="im">from</span> langchain_openai <span class="im">import</span> AzureChatOpenAI</span>
<span id="cb71-3"><a href="solution-proposal.html#cb71-3" aria-hidden="true"></a><span class="im">from</span> langchain_core.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb71-4"><a href="solution-proposal.html#cb71-4" aria-hidden="true"></a></span>
<span id="cb71-5"><a href="solution-proposal.html#cb71-5" aria-hidden="true"></a><span class="co"># Initialize the client once</span></span>
<span id="cb71-6"><a href="solution-proposal.html#cb71-6" aria-hidden="true"></a>client <span class="op">=</span> AzureChatOpenAI(</span>
<span id="cb71-7"><a href="solution-proposal.html#cb71-7" aria-hidden="true"></a>    api_key<span class="op">=</span>userdata.get(<span class="st">&quot;AZURE_OPENAI_API_KEY&quot;</span>),</span>
<span id="cb71-8"><a href="solution-proposal.html#cb71-8" aria-hidden="true"></a>    azure_endpoint<span class="op">=</span><span class="st">&quot;https://gpt-ban443-1.openai.azure.com/&quot;</span>,</span>
<span id="cb71-9"><a href="solution-proposal.html#cb71-9" aria-hidden="true"></a>    api_version<span class="op">=</span><span class="st">&quot;2025-01-01-preview&quot;</span>,</span>
<span id="cb71-10"><a href="solution-proposal.html#cb71-10" aria-hidden="true"></a>    azure_deployment<span class="op">=</span><span class="st">&quot;Group01&quot;</span>,</span>
<span id="cb71-11"><a href="solution-proposal.html#cb71-11" aria-hidden="true"></a>    temperature<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb71-12"><a href="solution-proposal.html#cb71-12" aria-hidden="true"></a>)</span>
<span id="cb71-13"><a href="solution-proposal.html#cb71-13" aria-hidden="true"></a></span>
<span id="cb71-14"><a href="solution-proposal.html#cb71-14" aria-hidden="true"></a><span class="kw">def</span> ask_group01_langchain(system_prompt: <span class="bu">str</span>, user_prompt: <span class="bu">str</span>, temperature: <span class="bu">float</span> <span class="op">=</span> <span class="dv">0</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb71-15"><a href="solution-proposal.html#cb71-15" aria-hidden="true"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb71-16"><a href="solution-proposal.html#cb71-16" aria-hidden="true"></a><span class="co">    Send a chat request to the Group01 Azure OpenAI deployment using LangChain.</span></span>
<span id="cb71-17"><a href="solution-proposal.html#cb71-17" aria-hidden="true"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb71-18"><a href="solution-proposal.html#cb71-18" aria-hidden="true"></a>    messages <span class="op">=</span> [</span>
<span id="cb71-19"><a href="solution-proposal.html#cb71-19" aria-hidden="true"></a>        (<span class="st">&quot;system&quot;</span>, system_prompt),</span>
<span id="cb71-20"><a href="solution-proposal.html#cb71-20" aria-hidden="true"></a>        (<span class="st">&quot;human&quot;</span>, user_prompt),</span>
<span id="cb71-21"><a href="solution-proposal.html#cb71-21" aria-hidden="true"></a>    ]</span>
<span id="cb71-22"><a href="solution-proposal.html#cb71-22" aria-hidden="true"></a>    ai_msg <span class="op">=</span> client.invoke(messages)</span>
<span id="cb71-23"><a href="solution-proposal.html#cb71-23" aria-hidden="true"></a>    <span class="cf">return</span> ai_msg.content</span>
<span id="cb71-24"><a href="solution-proposal.html#cb71-24" aria-hidden="true"></a></span>
<span id="cb71-25"><a href="solution-proposal.html#cb71-25" aria-hidden="true"></a><span class="co"># Example use</span></span>
<span id="cb71-26"><a href="solution-proposal.html#cb71-26" aria-hidden="true"></a>reply <span class="op">=</span> ask_group01_langchain(system_prompt, <span class="st">&quot;Who are lecturing in the course BAN443?&quot;</span>)</span>
<span id="cb71-27"><a href="solution-proposal.html#cb71-27" aria-hidden="true"></a><span class="bu">print</span>(reply)</span></code></pre></div>
</div>
</div>
<div id="question-3-analyze-letterboxd-dataset" class="section level3 hasAnchor" number="8.1.3">
<h3><span class="header-section-number">8.1.3</span> Question 3: Analyze Letterboxd dataset<a href="solution-proposal.html#question-3-analyze-letterboxd-dataset" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The students got some code to start with, to make it easier to download the dataset. As with the previous question, all you really need to do is to find the necessary code in a previous notebook or on the course website and tweak it a bit.</p>
<p>There are several code snippets we could use:
- We could make an LLM function just return a string with what we want (OpenAI package or LangChain package)
- We could use the structured output functionality (again, works both with OpenAI package and LangChain package)</p>
<p>I do both below.</p>
<p>Note that the way to answer both question a and b are the same, so I will show the approach for question b (several different ways). For question a you would just add to the prompt some definition of what you think a good or bad movie is, and make it return (extract) either LIKE or DISLIKE (for example).</p>
<div id="lets-first-get-the-data" class="section level4 hasAnchor" number="8.1.3.1">
<h4><span class="header-section-number">8.1.3.1</span> Let’s first get the data<a href="solution-proposal.html#lets-first-get-the-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb72"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="solution-proposal.html#cb72-1" aria-hidden="true"></a><span class="co"># First, let&#39;s get the data</span></span>
<span id="cb72-2"><a href="solution-proposal.html#cb72-2" aria-hidden="true"></a><span class="im">import</span> kagglehub</span>
<span id="cb72-3"><a href="solution-proposal.html#cb72-3" aria-hidden="true"></a><span class="im">from</span> google.colab <span class="im">import</span> userdata</span>
<span id="cb72-4"><a href="solution-proposal.html#cb72-4" aria-hidden="true"></a><span class="im">import</span> os</span>
<span id="cb72-5"><a href="solution-proposal.html#cb72-5" aria-hidden="true"></a></span>
<span id="cb72-6"><a href="solution-proposal.html#cb72-6" aria-hidden="true"></a><span class="co"># Information on how to get the api username and key: https://www.kaggle.com/docs/api</span></span>
<span id="cb72-7"><a href="solution-proposal.html#cb72-7" aria-hidden="true"></a>os.environ[<span class="st">&quot;KAGGLE_USERNAME&quot;</span>] <span class="op">=</span> <span class="st">&quot;eirikberger&quot;</span></span>
<span id="cb72-8"><a href="solution-proposal.html#cb72-8" aria-hidden="true"></a>os.environ[<span class="st">&quot;KAGGLE_KEY&quot;</span>] <span class="op">=</span> userdata.get(<span class="st">&#39;kaggle&#39;</span>)</span>
<span id="cb72-9"><a href="solution-proposal.html#cb72-9" aria-hidden="true"></a></span>
<span id="cb72-10"><a href="solution-proposal.html#cb72-10" aria-hidden="true"></a><span class="co"># Download latest version</span></span>
<span id="cb72-11"><a href="solution-proposal.html#cb72-11" aria-hidden="true"></a>path <span class="op">=</span> kagglehub.dataset_download(<span class="st">&quot;samlearner/letterboxd-movie-ratings-data&quot;</span>)</span>
<span id="cb72-12"><a href="solution-proposal.html#cb72-12" aria-hidden="true"></a></span>
<span id="cb72-13"><a href="solution-proposal.html#cb72-13" aria-hidden="true"></a><span class="co"># Then, we import the dataset and print a part of it</span></span>
<span id="cb72-14"><a href="solution-proposal.html#cb72-14" aria-hidden="true"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb72-15"><a href="solution-proposal.html#cb72-15" aria-hidden="true"></a></span>
<span id="cb72-16"><a href="solution-proposal.html#cb72-16" aria-hidden="true"></a>file_path <span class="op">=</span> path <span class="op">+</span> <span class="st">&quot;/movie_data.csv&quot;</span></span>
<span id="cb72-17"><a href="solution-proposal.html#cb72-17" aria-hidden="true"></a></span>
<span id="cb72-18"><a href="solution-proposal.html#cb72-18" aria-hidden="true"></a>df <span class="op">=</span> pd.read_csv(</span>
<span id="cb72-19"><a href="solution-proposal.html#cb72-19" aria-hidden="true"></a>    file_path,</span>
<span id="cb72-20"><a href="solution-proposal.html#cb72-20" aria-hidden="true"></a>    sep<span class="op">=</span><span class="st">&quot;,&quot;</span>,</span>
<span id="cb72-21"><a href="solution-proposal.html#cb72-21" aria-hidden="true"></a>    on_bad_lines<span class="op">=</span><span class="st">&quot;warn&quot;</span>,</span>
<span id="cb72-22"><a href="solution-proposal.html#cb72-22" aria-hidden="true"></a>    quoting<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb72-23"><a href="solution-proposal.html#cb72-23" aria-hidden="true"></a>    encoding<span class="op">=</span><span class="st">&quot;utf-8&quot;</span>,</span>
<span id="cb72-24"><a href="solution-proposal.html#cb72-24" aria-hidden="true"></a>    lineterminator<span class="op">=</span><span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span></span>
<span id="cb72-25"><a href="solution-proposal.html#cb72-25" aria-hidden="true"></a>)</span>
<span id="cb72-26"><a href="solution-proposal.html#cb72-26" aria-hidden="true"></a>df.head(<span class="dv">5</span>)</span>
<span id="cb72-27"><a href="solution-proposal.html#cb72-27" aria-hidden="true"></a></span>
<span id="cb72-28"><a href="solution-proposal.html#cb72-28" aria-hidden="true"></a><span class="co"># I extract a random subsample of movies from Norway, and I keep only the title and overview</span></span>
<span id="cb72-29"><a href="solution-proposal.html#cb72-29" aria-hidden="true"></a>norway_movie_sample <span class="op">=</span> df[df.production_countries <span class="op">==</span> <span class="st">&#39;[&quot;Norway&quot;]&#39;</span>].sample(<span class="dv">10</span>)</span>
<span id="cb72-30"><a href="solution-proposal.html#cb72-30" aria-hidden="true"></a>norway_movie_sample <span class="op">=</span> norway_movie_sample[[<span class="st">&#39;movie_title&#39;</span>, <span class="st">&#39;overview&#39;</span>]]</span>
<span id="cb72-31"><a href="solution-proposal.html#cb72-31" aria-hidden="true"></a>norway_movie_sample</span></code></pre></div>
</div>
<div id="structure-using-azure-openai-package" class="section level4 hasAnchor" number="8.1.3.2">
<h4><span class="header-section-number">8.1.3.2</span> Structure using Azure OpenAI package<a href="solution-proposal.html#structure-using-azure-openai-package" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb73"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="solution-proposal.html#cb73-1" aria-hidden="true"></a><span class="im">from</span> openai <span class="im">import</span> AzureOpenAI</span>
<span id="cb73-2"><a href="solution-proposal.html#cb73-2" aria-hidden="true"></a><span class="im">from</span> google.colab <span class="im">import</span> userdata</span>
<span id="cb73-3"><a href="solution-proposal.html#cb73-3" aria-hidden="true"></a></span>
<span id="cb73-4"><a href="solution-proposal.html#cb73-4" aria-hidden="true"></a>client <span class="op">=</span> AzureOpenAI(</span>
<span id="cb73-5"><a href="solution-proposal.html#cb73-5" aria-hidden="true"></a>    api_key<span class="op">=</span>userdata.get(<span class="st">&#39;AZURE_OPENAI_API_KEY&#39;</span>),</span>
<span id="cb73-6"><a href="solution-proposal.html#cb73-6" aria-hidden="true"></a>    api_version<span class="op">=</span><span class="st">&quot;2025-01-01-preview&quot;</span>,</span>
<span id="cb73-7"><a href="solution-proposal.html#cb73-7" aria-hidden="true"></a>    base_url<span class="op">=</span><span class="st">&quot;https://gpt-ban443-1.openai.azure.com/openai/deployments/Group01/&quot;</span></span>
<span id="cb73-8"><a href="solution-proposal.html#cb73-8" aria-hidden="true"></a>)</span>
<span id="cb73-9"><a href="solution-proposal.html#cb73-9" aria-hidden="true"></a></span>
<span id="cb73-10"><a href="solution-proposal.html#cb73-10" aria-hidden="true"></a><span class="kw">def</span> get_information(input_text):</span>
<span id="cb73-11"><a href="solution-proposal.html#cb73-11" aria-hidden="true"></a>    <span class="co"># Simple chat completion</span></span>
<span id="cb73-12"><a href="solution-proposal.html#cb73-12" aria-hidden="true"></a>    response <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb73-13"><a href="solution-proposal.html#cb73-13" aria-hidden="true"></a>        model<span class="op">=</span><span class="st">&quot;Group01&quot;</span>,</span>
<span id="cb73-14"><a href="solution-proposal.html#cb73-14" aria-hidden="true"></a>        messages<span class="op">=</span>[</span>
<span id="cb73-15"><a href="solution-proposal.html#cb73-15" aria-hidden="true"></a>            {<span class="st">&quot;role&quot;</span>: <span class="st">&quot;system&quot;</span>, <span class="st">&quot;content&quot;</span>: <span class="st">&quot;&quot;&quot;You are a helpful assistant. Extract the name of the main character,</span></span>
<span id="cb73-16"><a href="solution-proposal.html#cb73-16" aria-hidden="true"></a><span class="st">            and nothing else. If not is provided, return nothing&quot;&quot;&quot;</span>},</span>
<span id="cb73-17"><a href="solution-proposal.html#cb73-17" aria-hidden="true"></a>            {<span class="st">&quot;role&quot;</span>: <span class="st">&quot;user&quot;</span>, <span class="st">&quot;content&quot;</span>: input_text}</span>
<span id="cb73-18"><a href="solution-proposal.html#cb73-18" aria-hidden="true"></a>        ],</span>
<span id="cb73-19"><a href="solution-proposal.html#cb73-19" aria-hidden="true"></a>        temperature<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb73-20"><a href="solution-proposal.html#cb73-20" aria-hidden="true"></a>        max_tokens<span class="op">=</span><span class="dv">500</span></span>
<span id="cb73-21"><a href="solution-proposal.html#cb73-21" aria-hidden="true"></a>    )</span>
<span id="cb73-22"><a href="solution-proposal.html#cb73-22" aria-hidden="true"></a></span>
<span id="cb73-23"><a href="solution-proposal.html#cb73-23" aria-hidden="true"></a>    <span class="cf">return</span> response.choices[<span class="dv">0</span>].message.content</span>
<span id="cb73-24"><a href="solution-proposal.html#cb73-24" aria-hidden="true"></a></span>
<span id="cb73-25"><a href="solution-proposal.html#cb73-25" aria-hidden="true"></a><span class="co"># Test the function</span></span>
<span id="cb73-26"><a href="solution-proposal.html#cb73-26" aria-hidden="true"></a>get_information(<span class="st">&quot;Norwegian Ninja is the true story of how Commander Arne Treholt and his Ninja Force saved Norway during the Cold War. In 1983 the Ninja Force discovers that the sinister NATO force Stay Behind, who take charge in times of war and emergency, are planning a coup-d&#39;état in peacetime. Treholt and the Ninjas see only one solution: a full can of whoop-ass.&quot;</span>)</span></code></pre></div>
<p>Great. We will now loop over the dataframe we had above and save the response from the LLM as a new variable.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="solution-proposal.html#cb74-1" aria-hidden="true"></a><span class="co"># The &quot;apply&quot; part uses our function on all the &quot;overview&quot;</span></span>
<span id="cb74-2"><a href="solution-proposal.html#cb74-2" aria-hidden="true"></a><span class="co"># rows in our dataset and create a new variable called &quot;main_character&quot; where it stores</span></span>
<span id="cb74-3"><a href="solution-proposal.html#cb74-3" aria-hidden="true"></a><span class="co"># the output from the function</span></span>
<span id="cb74-4"><a href="solution-proposal.html#cb74-4" aria-hidden="true"></a>norway_movie_sample[<span class="st">&#39;main_character&#39;</span>] <span class="op">=</span> norway_movie_sample[<span class="st">&#39;overview&#39;</span>].<span class="bu">apply</span>(get_information)</span>
<span id="cb74-5"><a href="solution-proposal.html#cb74-5" aria-hidden="true"></a>norway_movie_sample.head(<span class="dv">5</span>)</span></code></pre></div>
</div>
<div id="a-somewhat-more-advanced-langchain-example" class="section level4 hasAnchor" number="8.1.3.3">
<h4><span class="header-section-number">8.1.3.3</span> A somewhat more advanced LangChain example<a href="solution-proposal.html#a-somewhat-more-advanced-langchain-example" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb75"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="solution-proposal.html#cb75-1" aria-hidden="true"></a><span class="co"># LangChain standard OpenAI setup</span></span>
<span id="cb75-2"><a href="solution-proposal.html#cb75-2" aria-hidden="true"></a><span class="im">from</span> langchain_openai <span class="im">import</span> AzureChatOpenAI</span>
<span id="cb75-3"><a href="solution-proposal.html#cb75-3" aria-hidden="true"></a><span class="im">from</span> google.colab <span class="im">import</span> userdata</span>
<span id="cb75-4"><a href="solution-proposal.html#cb75-4" aria-hidden="true"></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb75-5"><a href="solution-proposal.html#cb75-5" aria-hidden="true"></a><span class="im">from</span> typing <span class="im">import</span> Optional, List</span>
<span id="cb75-6"><a href="solution-proposal.html#cb75-6" aria-hidden="true"></a><span class="im">from</span> langchain_core.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb75-7"><a href="solution-proposal.html#cb75-7" aria-hidden="true"></a></span>
<span id="cb75-8"><a href="solution-proposal.html#cb75-8" aria-hidden="true"></a>client <span class="op">=</span> AzureChatOpenAI(</span>
<span id="cb75-9"><a href="solution-proposal.html#cb75-9" aria-hidden="true"></a>    api_key<span class="op">=</span>userdata.get(<span class="st">&quot;AZURE_OPENAI_API_KEY&quot;</span>),</span>
<span id="cb75-10"><a href="solution-proposal.html#cb75-10" aria-hidden="true"></a>    azure_endpoint<span class="op">=</span><span class="st">&quot;https://gpt-ban443-1.openai.azure.com/&quot;</span>,</span>
<span id="cb75-11"><a href="solution-proposal.html#cb75-11" aria-hidden="true"></a>    api_version<span class="op">=</span><span class="st">&quot;2025-01-01-preview&quot;</span>,</span>
<span id="cb75-12"><a href="solution-proposal.html#cb75-12" aria-hidden="true"></a>    azure_deployment<span class="op">=</span><span class="st">&quot;Group01&quot;</span>,</span>
<span id="cb75-13"><a href="solution-proposal.html#cb75-13" aria-hidden="true"></a>    temperature<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb75-14"><a href="solution-proposal.html#cb75-14" aria-hidden="true"></a>)</span>
<span id="cb75-15"><a href="solution-proposal.html#cb75-15" aria-hidden="true"></a></span>
<span id="cb75-16"><a href="solution-proposal.html#cb75-16" aria-hidden="true"></a><span class="co"># Define the structure you want to extract</span></span>
<span id="cb75-17"><a href="solution-proposal.html#cb75-17" aria-hidden="true"></a><span class="kw">class</span> Person(BaseModel):</span>
<span id="cb75-18"><a href="solution-proposal.html#cb75-18" aria-hidden="true"></a>    <span class="co">&quot;&quot;&quot;Information about a person from text.&quot;&quot;&quot;</span></span>
<span id="cb75-19"><a href="solution-proposal.html#cb75-19" aria-hidden="true"></a>    name: Optional[<span class="bu">str</span>] <span class="op">=</span> Field(default<span class="op">=</span><span class="va">None</span>, description<span class="op">=</span><span class="st">&quot;Name of main character described.&quot;</span>)</span>
<span id="cb75-20"><a href="solution-proposal.html#cb75-20" aria-hidden="true"></a></span>
<span id="cb75-21"><a href="solution-proposal.html#cb75-21" aria-hidden="true"></a><span class="co"># Create a prompt template</span></span>
<span id="cb75-22"><a href="solution-proposal.html#cb75-22" aria-hidden="true"></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb75-23"><a href="solution-proposal.html#cb75-23" aria-hidden="true"></a>    (<span class="st">&quot;system&quot;</span>, <span class="st">&quot;You are an expert at extracting person information from text.&quot;</span>),</span>
<span id="cb75-24"><a href="solution-proposal.html#cb75-24" aria-hidden="true"></a>    (<span class="st">&quot;human&quot;</span>, <span class="st">&quot;</span><span class="sc">{text}</span><span class="st">&quot;</span>)</span>
<span id="cb75-25"><a href="solution-proposal.html#cb75-25" aria-hidden="true"></a>])</span>
<span id="cb75-26"><a href="solution-proposal.html#cb75-26" aria-hidden="true"></a></span>
<span id="cb75-27"><a href="solution-proposal.html#cb75-27" aria-hidden="true"></a><span class="co"># Create the structured extractor</span></span>
<span id="cb75-28"><a href="solution-proposal.html#cb75-28" aria-hidden="true"></a>extractor <span class="op">=</span> prompt <span class="op">|</span> client.with_structured_output(</span>
<span id="cb75-29"><a href="solution-proposal.html#cb75-29" aria-hidden="true"></a>    schema<span class="op">=</span>Person</span>
<span id="cb75-30"><a href="solution-proposal.html#cb75-30" aria-hidden="true"></a>)</span>
<span id="cb75-31"><a href="solution-proposal.html#cb75-31" aria-hidden="true"></a></span>
<span id="cb75-32"><a href="solution-proposal.html#cb75-32" aria-hidden="true"></a><span class="co"># Test the extraction</span></span>
<span id="cb75-33"><a href="solution-proposal.html#cb75-33" aria-hidden="true"></a>test_response <span class="op">=</span> extractor.invoke(<span class="st">&quot;Norwegian Ninja is the true story of how Commander Arne Treholt and his Ninja Force saved Norway during the Cold War. In 1983 the Ninja Force discovers that the sinister NATO force Stay Behind, who take charge in times of war and emergency, are planning a coup-d&#39;état in peacetime. Treholt and the Ninjas see only one solution: a full can of whoop-ass.&quot;</span>)</span>
<span id="cb75-34"><a href="solution-proposal.html#cb75-34" aria-hidden="true"></a>test_response</span></code></pre></div>
<p>Let’s get the structured output as text, by first getting JSON format as string, then loading the JSON and selecting the “name” element:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="solution-proposal.html#cb76-1" aria-hidden="true"></a><span class="im">import</span> json</span>
<span id="cb76-2"><a href="solution-proposal.html#cb76-2" aria-hidden="true"></a></span>
<span id="cb76-3"><a href="solution-proposal.html#cb76-3" aria-hidden="true"></a>text_response <span class="op">=</span> test_response.model_dump_json()</span>
<span id="cb76-4"><a href="solution-proposal.html#cb76-4" aria-hidden="true"></a>text_response <span class="op">=</span> json.loads(text_response)</span>
<span id="cb76-5"><a href="solution-proposal.html#cb76-5" aria-hidden="true"></a>text_response <span class="op">=</span> text_response[<span class="st">&quot;name&quot;</span>]</span>
<span id="cb76-6"><a href="solution-proposal.html#cb76-6" aria-hidden="true"></a>text_response</span></code></pre></div>
<p>We can run it on all the rows in our dataframe and save the variable back in at least two different ways:</p>
</div>
<div id="lets-do-it-by-making-a-function" class="section level4 hasAnchor" number="8.1.3.4">
<h4><span class="header-section-number">8.1.3.4</span> Let’s do it by making a function<a href="solution-proposal.html#lets-do-it-by-making-a-function" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb77"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="solution-proposal.html#cb77-1" aria-hidden="true"></a><span class="co"># First, define a function</span></span>
<span id="cb77-2"><a href="solution-proposal.html#cb77-2" aria-hidden="true"></a><span class="kw">def</span> extract_information_langchain_1(text_input):</span>
<span id="cb77-3"><a href="solution-proposal.html#cb77-3" aria-hidden="true"></a>    response <span class="op">=</span> extractor.invoke(text_input)</span>
<span id="cb77-4"><a href="solution-proposal.html#cb77-4" aria-hidden="true"></a>    text_response <span class="op">=</span> response.model_dump_json()</span>
<span id="cb77-5"><a href="solution-proposal.html#cb77-5" aria-hidden="true"></a>    text_response <span class="op">=</span> json.loads(text_response)</span>
<span id="cb77-6"><a href="solution-proposal.html#cb77-6" aria-hidden="true"></a>    text_response <span class="op">=</span> text_response[<span class="st">&quot;name&quot;</span>]</span>
<span id="cb77-7"><a href="solution-proposal.html#cb77-7" aria-hidden="true"></a>    text_response</span>
<span id="cb77-8"><a href="solution-proposal.html#cb77-8" aria-hidden="true"></a>    <span class="cf">return</span> text_response</span>
<span id="cb77-9"><a href="solution-proposal.html#cb77-9" aria-hidden="true"></a></span>
<span id="cb77-10"><a href="solution-proposal.html#cb77-10" aria-hidden="true"></a><span class="co"># Then run it on all the &quot;overview&quot; rows and save it to a new variable</span></span>
<span id="cb77-11"><a href="solution-proposal.html#cb77-11" aria-hidden="true"></a>norway_movie_sample[<span class="st">&#39;main_character_langchain_1&#39;</span>] <span class="op">=</span> norway_movie_sample[<span class="st">&#39;overview&#39;</span>].<span class="bu">apply</span>(extract_information_langchain_1)</span>
<span id="cb77-12"><a href="solution-proposal.html#cb77-12" aria-hidden="true"></a>norway_movie_sample.head(<span class="dv">5</span>)</span></code></pre></div>
<div id="or-using-the-batch-mode-in-langchain" class="section level5 hasAnchor" number="8.1.3.4.1">
<h5><span class="header-section-number">8.1.3.4.1</span> Or using the batch mode in LangChain<a href="solution-proposal.html#or-using-the-batch-mode-in-langchain" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<div class="sourceCode" id="cb78"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="solution-proposal.html#cb78-1" aria-hidden="true"></a><span class="co"># Convert column to list of dicts with the right input key</span></span>
<span id="cb78-2"><a href="solution-proposal.html#cb78-2" aria-hidden="true"></a>inputs <span class="op">=</span> [{<span class="st">&quot;text&quot;</span>: t} <span class="cf">for</span> t <span class="kw">in</span> norway_movie_sample[<span class="st">&quot;overview&quot;</span>].tolist()</span>
<span id="cb78-3"><a href="solution-proposal.html#cb78-3" aria-hidden="true"></a></span>
<span id="cb78-4"><a href="solution-proposal.html#cb78-4" aria-hidden="true"></a><span class="co"># Run in batch</span></span>
<span id="cb78-5"><a href="solution-proposal.html#cb78-5" aria-hidden="true"></a>extractions <span class="op">=</span> extractor.batch(inputs, {<span class="st">&quot;max_concurrency&quot;</span>: <span class="dv">5</span>})</span>
<span id="cb78-6"><a href="solution-proposal.html#cb78-6" aria-hidden="true"></a></span>
<span id="cb78-7"><a href="solution-proposal.html#cb78-7" aria-hidden="true"></a><span class="co"># Save results back into a new column</span></span>
<span id="cb78-8"><a href="solution-proposal.html#cb78-8" aria-hidden="true"></a><span class="co"># Note that the last expression there looks a bit strange, but a) ChatGPT could help you with that part</span></span>
<span id="cb78-9"><a href="solution-proposal.html#cb78-9" aria-hidden="true"></a><span class="co"># as long as you can tell it what the &#39;extractions&#39; is and what you want to do with it.</span></span>
<span id="cb78-10"><a href="solution-proposal.html#cb78-10" aria-hidden="true"></a><span class="co"># ... or you can just use this code here.</span></span>
<span id="cb78-11"><a href="solution-proposal.html#cb78-11" aria-hidden="true"></a>norway_movie_sample[<span class="st">&quot;main_character_langchain_2&quot;</span>] <span class="op">=</span> [r.model_dump()[<span class="st">&quot;name&quot;</span>] <span class="cf">for</span> r <span class="kw">in</span> extractions]</span>
<span id="cb78-12"><a href="solution-proposal.html#cb78-12" aria-hidden="true"></a></span>
<span id="cb78-13"><a href="solution-proposal.html#cb78-13" aria-hidden="true"></a>norway_movie_sample</span></code></pre></div>
</div>
</div>
</div>
<div id="question-4" class="section level3 hasAnchor" number="8.1.4">
<h3><span class="header-section-number">8.1.4</span> Question 4<a href="solution-proposal.html#question-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>I skip this question, as it’s fairly open and also it probably uses much of the same code as above. Let me know if you have questions!</p>
</div>
</div>
<div id="lab-2-1" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Lab 2<a href="solution-proposal.html#lab-2-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><a href="https://colab.research.google.com/drive/1CWYwP_Sj6D83x67tCvU88V3R7eyHVKiM?usp=sharing" target="_blank">
<img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a></p>
<div id="question-1-journalist-llm" class="section level3 hasAnchor" number="8.2.1">
<h3><span class="header-section-number">8.2.1</span> Question 1: Journalist LLM<a href="solution-proposal.html#question-1-journalist-llm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This question asks us to create a function that helps journalists summarize articles. The function should take text input and return a summary in a structured format.</p>
<div id="basic-journalist-function" class="section level4 hasAnchor" number="8.2.1.1">
<h4><span class="header-section-number">8.2.1.1</span> Basic Journalist Function<a href="solution-proposal.html#basic-journalist-function" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="solution-proposal.html#cb79-1" aria-hidden="true"></a><span class="co"># LangChain Azure OpenAI setup</span></span>
<span id="cb79-2"><a href="solution-proposal.html#cb79-2" aria-hidden="true"></a><span class="im">from</span> langchain_openai <span class="im">import</span> AzureChatOpenAI</span>
<span id="cb79-3"><a href="solution-proposal.html#cb79-3" aria-hidden="true"></a><span class="im">from</span> google.colab <span class="im">import</span> userdata</span>
<span id="cb79-4"><a href="solution-proposal.html#cb79-4" aria-hidden="true"></a></span>
<span id="cb79-5"><a href="solution-proposal.html#cb79-5" aria-hidden="true"></a><span class="co"># Initialize the Azure OpenAI client</span></span>
<span id="cb79-6"><a href="solution-proposal.html#cb79-6" aria-hidden="true"></a>client <span class="op">=</span> AzureChatOpenAI(</span>
<span id="cb79-7"><a href="solution-proposal.html#cb79-7" aria-hidden="true"></a>    api_key<span class="op">=</span>userdata.get(<span class="st">&quot;new_azure_gpt5&quot;</span>),</span>
<span id="cb79-8"><a href="solution-proposal.html#cb79-8" aria-hidden="true"></a>    azure_endpoint<span class="op">=</span><span class="st">&quot;https://ban443-1.openai.azure.com/&quot;</span>,</span>
<span id="cb79-9"><a href="solution-proposal.html#cb79-9" aria-hidden="true"></a>    api_version<span class="op">=</span><span class="st">&quot;2025-03-01-preview&quot;</span>,</span>
<span id="cb79-10"><a href="solution-proposal.html#cb79-10" aria-hidden="true"></a>    azure_deployment<span class="op">=</span><span class="st">&quot;Group01&quot;</span>,</span>
<span id="cb79-11"><a href="solution-proposal.html#cb79-11" aria-hidden="true"></a>)</span>
<span id="cb79-12"><a href="solution-proposal.html#cb79-12" aria-hidden="true"></a></span>
<span id="cb79-13"><a href="solution-proposal.html#cb79-13" aria-hidden="true"></a><span class="kw">def</span> journalist_task(article: <span class="bu">str</span>):</span>
<span id="cb79-14"><a href="solution-proposal.html#cb79-14" aria-hidden="true"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb79-15"><a href="solution-proposal.html#cb79-15" aria-hidden="true"></a><span class="co">    Function to summarize articles for journalists.</span></span>
<span id="cb79-16"><a href="solution-proposal.html#cb79-16" aria-hidden="true"></a><span class="co">    Takes an article text and returns a structured summary with bullet points.</span></span>
<span id="cb79-17"><a href="solution-proposal.html#cb79-17" aria-hidden="true"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb79-18"><a href="solution-proposal.html#cb79-18" aria-hidden="true"></a>    msgs <span class="op">=</span> [</span>
<span id="cb79-19"><a href="solution-proposal.html#cb79-19" aria-hidden="true"></a>        (<span class="st">&quot;system&quot;</span>, <span class="st">&quot;&quot;&quot;</span></span>
<span id="cb79-20"><a href="solution-proposal.html#cb79-20" aria-hidden="true"></a><span class="st">              You are a helpful assistant that specializes in summarizing articles for journalists, in the language the article was written.</span></span>
<span id="cb79-21"><a href="solution-proposal.html#cb79-21" aria-hidden="true"></a><span class="st">              This means you put the main points of the article in bullet points. It would look something like this:</span></span>
<span id="cb79-22"><a href="solution-proposal.html#cb79-22" aria-hidden="true"></a><span class="st">              Title for Article</span></span>
<span id="cb79-23"><a href="solution-proposal.html#cb79-23" aria-hidden="true"></a><span class="st">              * Point 1</span></span>
<span id="cb79-24"><a href="solution-proposal.html#cb79-24" aria-hidden="true"></a><span class="st">              * Point 2</span></span>
<span id="cb79-25"><a href="solution-proposal.html#cb79-25" aria-hidden="true"></a><span class="st">              * Point 3</span></span>
<span id="cb79-26"><a href="solution-proposal.html#cb79-26" aria-hidden="true"></a><span class="st">              * ...</span></span>
<span id="cb79-27"><a href="solution-proposal.html#cb79-27" aria-hidden="true"></a></span>
<span id="cb79-28"><a href="solution-proposal.html#cb79-28" aria-hidden="true"></a><span class="st">              This could for example be:</span></span>
<span id="cb79-29"><a href="solution-proposal.html#cb79-29" aria-hidden="true"></a><span class="st">              Donald Trump Wins Election</span></span>
<span id="cb79-30"><a href="solution-proposal.html#cb79-30" aria-hidden="true"></a><span class="st">              * Donald Trump has become the president of The Unites States of America</span></span>
<span id="cb79-31"><a href="solution-proposal.html#cb79-31" aria-hidden="true"></a><span class="st">              * The Republican party got x amount of votes, and y mandates</span></span>
<span id="cb79-32"><a href="solution-proposal.html#cb79-32" aria-hidden="true"></a><span class="st">              * &lt;An important quote from the article&gt;</span></span>
<span id="cb79-33"><a href="solution-proposal.html#cb79-33" aria-hidden="true"></a><span class="st">              * ...</span></span>
<span id="cb79-34"><a href="solution-proposal.html#cb79-34" aria-hidden="true"></a><span class="st">      &quot;&quot;&quot;</span></span>
<span id="cb79-35"><a href="solution-proposal.html#cb79-35" aria-hidden="true"></a>      ),</span>
<span id="cb79-36"><a href="solution-proposal.html#cb79-36" aria-hidden="true"></a>        (<span class="st">&quot;human&quot;</span>, <span class="ss">f&quot;Make me a summary of this article with 200 to 300 words: </span><span class="sc">{</span>article<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb79-37"><a href="solution-proposal.html#cb79-37" aria-hidden="true"></a>    ]</span>
<span id="cb79-38"><a href="solution-proposal.html#cb79-38" aria-hidden="true"></a></span>
<span id="cb79-39"><a href="solution-proposal.html#cb79-39" aria-hidden="true"></a>    <span class="co"># Use the responses API for cleaner output</span></span>
<span id="cb79-40"><a href="solution-proposal.html#cb79-40" aria-hidden="true"></a>    response <span class="op">=</span> client.invoke(msgs)</span>
<span id="cb79-41"><a href="solution-proposal.html#cb79-41" aria-hidden="true"></a>    <span class="cf">return</span> response.content</span>
<span id="cb79-42"><a href="solution-proposal.html#cb79-42" aria-hidden="true"></a></span>
<span id="cb79-43"><a href="solution-proposal.html#cb79-43" aria-hidden="true"></a><span class="co"># Example usage with a news article</span></span>
<span id="cb79-44"><a href="solution-proposal.html#cb79-44" aria-hidden="true"></a>answer <span class="op">=</span> journalist_task(</span>
<span id="cb79-45"><a href="solution-proposal.html#cb79-45" aria-hidden="true"></a>    <span class="st">&quot;&quot;&quot;</span></span>
<span id="cb79-46"><a href="solution-proposal.html#cb79-46" aria-hidden="true"></a><span class="st">    Israel has launched its long-threatened ground offensive into the densely packed streets of Gaza City, military officials have confirmed.</span></span>
<span id="cb79-47"><a href="solution-proposal.html#cb79-47" aria-hidden="true"></a><span class="st">    </span></span>
<span id="cb79-48"><a href="solution-proposal.html#cb79-48" aria-hidden="true"></a><span class="st">    One Israel Defense Forces (IDF) official said that troops had begun what he called the &quot;main phase&quot; of the offensive, with an overnight advance from the outskirts towards the city centre.</span></span>
<span id="cb79-49"><a href="solution-proposal.html#cb79-49" aria-hidden="true"></a><span class="st">    </span></span>
<span id="cb79-50"><a href="solution-proposal.html#cb79-50" aria-hidden="true"></a><span class="st">    &quot;Last night we began deepening our operations deeper into Gaza City,&quot; the IDF official said. &quot;It&#39;s a gradual thing. It is not a black or white thing. But yesterday was a big step forward … in operations on the ground.&quot;</span></span>
<span id="cb79-51"><a href="solution-proposal.html#cb79-51" aria-hidden="true"></a><span class="st">    &quot;&quot;&quot;</span></span>
<span id="cb79-52"><a href="solution-proposal.html#cb79-52" aria-hidden="true"></a>)</span>
<span id="cb79-53"><a href="solution-proposal.html#cb79-53" aria-hidden="true"></a><span class="bu">print</span>(answer)</span></code></pre></div>
</div>
<div id="enhanced-function-with-url-support" class="section level4 hasAnchor" number="8.2.1.2">
<h4><span class="header-section-number">8.2.1.2</span> Enhanced Function with URL Support<a href="solution-proposal.html#enhanced-function-with-url-support" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="solution-proposal.html#cb80-1" aria-hidden="true"></a><span class="co"># Additional functionality to summarize an article from a URL</span></span>
<span id="cb80-2"><a href="solution-proposal.html#cb80-2" aria-hidden="true"></a><span class="im">from</span> langchain_community.document_loaders <span class="im">import</span> WebBaseLoader</span>
<span id="cb80-3"><a href="solution-proposal.html#cb80-3" aria-hidden="true"></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb80-4"><a href="solution-proposal.html#cb80-4" aria-hidden="true"></a></span>
<span id="cb80-5"><a href="solution-proposal.html#cb80-5" aria-hidden="true"></a><span class="kw">def</span> summarize_from_link(url: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb80-6"><a href="solution-proposal.html#cb80-6" aria-hidden="true"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb80-7"><a href="solution-proposal.html#cb80-7" aria-hidden="true"></a><span class="co">    Function to load a webpage and summarize its content.</span></span>
<span id="cb80-8"><a href="solution-proposal.html#cb80-8" aria-hidden="true"></a><span class="co">    Takes a URL and returns a summary of the article.</span></span>
<span id="cb80-9"><a href="solution-proposal.html#cb80-9" aria-hidden="true"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb80-10"><a href="solution-proposal.html#cb80-10" aria-hidden="true"></a>    <span class="co"># Load webpage content using WebBaseLoader</span></span>
<span id="cb80-11"><a href="solution-proposal.html#cb80-11" aria-hidden="true"></a>    loader <span class="op">=</span> WebBaseLoader(url)</span>
<span id="cb80-12"><a href="solution-proposal.html#cb80-12" aria-hidden="true"></a>    docs <span class="op">=</span> loader.load()</span>
<span id="cb80-13"><a href="solution-proposal.html#cb80-13" aria-hidden="true"></a>    article_text <span class="op">=</span> docs[<span class="dv">0</span>].page_content</span>
<span id="cb80-14"><a href="solution-proposal.html#cb80-14" aria-hidden="true"></a></span>
<span id="cb80-15"><a href="solution-proposal.html#cb80-15" aria-hidden="true"></a>    <span class="co"># Build prompt template for summarization</span></span>
<span id="cb80-16"><a href="solution-proposal.html#cb80-16" aria-hidden="true"></a>    prompt <span class="op">=</span> ChatPromptTemplate.from_template(</span>
<span id="cb80-17"><a href="solution-proposal.html#cb80-17" aria-hidden="true"></a>        <span class="st">&quot;Summarize the following article clearly and concisely for a journalist:</span><span class="ch">\n\n</span><span class="sc">{article}</span><span class="st">&quot;</span></span>
<span id="cb80-18"><a href="solution-proposal.html#cb80-18" aria-hidden="true"></a>    )</span>
<span id="cb80-19"><a href="solution-proposal.html#cb80-19" aria-hidden="true"></a></span>
<span id="cb80-20"><a href="solution-proposal.html#cb80-20" aria-hidden="true"></a>    <span class="co"># Chain the prompt with the client using pipe syntax</span></span>
<span id="cb80-21"><a href="solution-proposal.html#cb80-21" aria-hidden="true"></a>    chain <span class="op">=</span> prompt <span class="op">|</span> client</span>
<span id="cb80-22"><a href="solution-proposal.html#cb80-22" aria-hidden="true"></a></span>
<span id="cb80-23"><a href="solution-proposal.html#cb80-23" aria-hidden="true"></a>    <span class="co"># Invoke with a dict matching the prompt&#39;s variable name</span></span>
<span id="cb80-24"><a href="solution-proposal.html#cb80-24" aria-hidden="true"></a>    result <span class="op">=</span> chain.invoke({<span class="st">&quot;article&quot;</span>: article_text})</span>
<span id="cb80-25"><a href="solution-proposal.html#cb80-25" aria-hidden="true"></a>    <span class="cf">return</span> result.content  <span class="co"># .content extracts the text</span></span>
<span id="cb80-26"><a href="solution-proposal.html#cb80-26" aria-hidden="true"></a></span>
<span id="cb80-27"><a href="solution-proposal.html#cb80-27" aria-hidden="true"></a><span class="co"># Example usage</span></span>
<span id="cb80-28"><a href="solution-proposal.html#cb80-28" aria-hidden="true"></a>summarize_from_link(<span class="st">&quot;https://www.nrk.no/rogaland/stortingsvalget-2025_-oljepionerene-og-kielland-nettverket-haper-pengene-kommer-i-statsbudsjettet-1.17551184&quot;</span>)</span></code></pre></div>
</div>
</div>
<div id="question-2-dataset-analysis" class="section level3 hasAnchor" number="8.2.2">
<h3><span class="header-section-number">8.2.2</span> Question 2: Dataset Analysis<a href="solution-proposal.html#question-2-dataset-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This question involves finding a dataset on Kaggle and using LangChain to analyze it. We’ll work with a COVID-19 NLP text classification dataset and extract multiple variables from each row.</p>
<div id="dataset-setup-and-basic-analysis" class="section level4 hasAnchor" number="8.2.2.1">
<h4><span class="header-section-number">8.2.2.1</span> Dataset Setup and Basic Analysis<a href="solution-proposal.html#dataset-setup-and-basic-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb81"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="solution-proposal.html#cb81-1" aria-hidden="true"></a><span class="im">import</span> kagglehub</span>
<span id="cb81-2"><a href="solution-proposal.html#cb81-2" aria-hidden="true"></a><span class="im">import</span> os</span>
<span id="cb81-3"><a href="solution-proposal.html#cb81-3" aria-hidden="true"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb81-4"><a href="solution-proposal.html#cb81-4" aria-hidden="true"></a></span>
<span id="cb81-5"><a href="solution-proposal.html#cb81-5" aria-hidden="true"></a><span class="co"># Set up Kaggle API credentials</span></span>
<span id="cb81-6"><a href="solution-proposal.html#cb81-6" aria-hidden="true"></a>os.environ[<span class="st">&quot;KAGGLE_USERNAME&quot;</span>] <span class="op">=</span> <span class="st">&quot;eirik.berger&quot;</span></span>
<span id="cb81-7"><a href="solution-proposal.html#cb81-7" aria-hidden="true"></a>os.environ[<span class="st">&quot;KAGGLE_KEY&quot;</span>] <span class="op">=</span> userdata.get(<span class="st">&#39;kaggle&#39;</span>)</span>
<span id="cb81-8"><a href="solution-proposal.html#cb81-8" aria-hidden="true"></a></span>
<span id="cb81-9"><a href="solution-proposal.html#cb81-9" aria-hidden="true"></a><span class="co"># Download the COVID-19 NLP text classification dataset</span></span>
<span id="cb81-10"><a href="solution-proposal.html#cb81-10" aria-hidden="true"></a>path <span class="op">=</span> kagglehub.dataset_download(<span class="st">&quot;datatattle/covid-19-nlp-text-classification&quot;</span>)</span>
<span id="cb81-11"><a href="solution-proposal.html#cb81-11" aria-hidden="true"></a></span>
<span id="cb81-12"><a href="solution-proposal.html#cb81-12" aria-hidden="true"></a><span class="co"># Load the dataset</span></span>
<span id="cb81-13"><a href="solution-proposal.html#cb81-13" aria-hidden="true"></a>file_path <span class="op">=</span> path <span class="op">+</span> <span class="st">&quot;/Corona_NLP_test.csv&quot;</span></span>
<span id="cb81-14"><a href="solution-proposal.html#cb81-14" aria-hidden="true"></a></span>
<span id="cb81-15"><a href="solution-proposal.html#cb81-15" aria-hidden="true"></a>df <span class="op">=</span> pd.read_csv(</span>
<span id="cb81-16"><a href="solution-proposal.html#cb81-16" aria-hidden="true"></a>    file_path,</span>
<span id="cb81-17"><a href="solution-proposal.html#cb81-17" aria-hidden="true"></a>    sep<span class="op">=</span><span class="st">&quot;,&quot;</span>,</span>
<span id="cb81-18"><a href="solution-proposal.html#cb81-18" aria-hidden="true"></a>    on_bad_lines<span class="op">=</span><span class="st">&quot;warn&quot;</span>,</span>
<span id="cb81-19"><a href="solution-proposal.html#cb81-19" aria-hidden="true"></a>    quoting<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb81-20"><a href="solution-proposal.html#cb81-20" aria-hidden="true"></a>    encoding<span class="op">=</span><span class="st">&quot;ISO-8859-1&quot;</span>,</span>
<span id="cb81-21"><a href="solution-proposal.html#cb81-21" aria-hidden="true"></a>    lineterminator<span class="op">=</span><span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span></span>
<span id="cb81-22"><a href="solution-proposal.html#cb81-22" aria-hidden="true"></a>)</span>
<span id="cb81-23"><a href="solution-proposal.html#cb81-23" aria-hidden="true"></a></span>
<span id="cb81-24"><a href="solution-proposal.html#cb81-24" aria-hidden="true"></a><span class="co"># Take a sample for analysis</span></span>
<span id="cb81-25"><a href="solution-proposal.html#cb81-25" aria-hidden="true"></a>df_head <span class="op">=</span> df.sample(<span class="dv">10</span>)</span></code></pre></div>
</div>
<div id="alternative-a-simple-categorization" class="section level4 hasAnchor" number="8.2.2.2">
<h4><span class="header-section-number">8.2.2.2</span> Alternative A: Simple Categorization<a href="solution-proposal.html#alternative-a-simple-categorization" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb82"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="solution-proposal.html#cb82-1" aria-hidden="true"></a><span class="kw">def</span> kaggle_task(news: <span class="bu">str</span>):</span>
<span id="cb82-2"><a href="solution-proposal.html#cb82-2" aria-hidden="true"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb82-3"><a href="solution-proposal.html#cb82-3" aria-hidden="true"></a><span class="co">    Simple function to categorize tweets into topics.</span></span>
<span id="cb82-4"><a href="solution-proposal.html#cb82-4" aria-hidden="true"></a><span class="co">    Returns only the category name as a string.</span></span>
<span id="cb82-5"><a href="solution-proposal.html#cb82-5" aria-hidden="true"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb82-6"><a href="solution-proposal.html#cb82-6" aria-hidden="true"></a>    msgs <span class="op">=</span> [</span>
<span id="cb82-7"><a href="solution-proposal.html#cb82-7" aria-hidden="true"></a>        (<span class="st">&quot;system&quot;</span>, <span class="st">&quot;You are a social media manager assistant and you are an expert in categorizing tweets into the category that fits it best for example environment, politics, etc.&quot;</span>),</span>
<span id="cb82-8"><a href="solution-proposal.html#cb82-8" aria-hidden="true"></a>        (<span class="st">&quot;human&quot;</span>, <span class="ss">f&quot;Categorize this tweet to the most fitting category, only return the text of the most fitting category: </span><span class="sc">{</span>news<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb82-9"><a href="solution-proposal.html#cb82-9" aria-hidden="true"></a>    ]</span>
<span id="cb82-10"><a href="solution-proposal.html#cb82-10" aria-hidden="true"></a></span>
<span id="cb82-11"><a href="solution-proposal.html#cb82-11" aria-hidden="true"></a>    <span class="co"># Use the responses API for cleaner output</span></span>
<span id="cb82-12"><a href="solution-proposal.html#cb82-12" aria-hidden="true"></a>    response <span class="op">=</span> client.invoke(msgs)</span>
<span id="cb82-13"><a href="solution-proposal.html#cb82-13" aria-hidden="true"></a>    <span class="cf">return</span> response.content</span>
<span id="cb82-14"><a href="solution-proposal.html#cb82-14" aria-hidden="true"></a></span>
<span id="cb82-15"><a href="solution-proposal.html#cb82-15" aria-hidden="true"></a><span class="co"># Apply categorization to the sample data</span></span>
<span id="cb82-16"><a href="solution-proposal.html#cb82-16" aria-hidden="true"></a>df_head[<span class="st">&#39;Category&#39;</span>] <span class="op">=</span> df_head[<span class="st">&#39;OriginalTweet&#39;</span>].<span class="bu">apply</span>(kaggle_task)</span>
<span id="cb82-17"><a href="solution-proposal.html#cb82-17" aria-hidden="true"></a>df_head.head(<span class="dv">5</span>)</span></code></pre></div>
</div>
<div id="alternative-b-structured-data-extraction" class="section level4 hasAnchor" number="8.2.2.3">
<h4><span class="header-section-number">8.2.2.3</span> Alternative B: Structured Data Extraction<a href="solution-proposal.html#alternative-b-structured-data-extraction" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="solution-proposal.html#cb83-1" aria-hidden="true"></a><span class="im">from</span> langchain_openai <span class="im">import</span> AzureChatOpenAI</span>
<span id="cb83-2"><a href="solution-proposal.html#cb83-2" aria-hidden="true"></a><span class="im">from</span> langchain_core.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb83-3"><a href="solution-proposal.html#cb83-3" aria-hidden="true"></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb83-4"><a href="solution-proposal.html#cb83-4" aria-hidden="true"></a><span class="im">from</span> typing <span class="im">import</span> Optional, List</span>
<span id="cb83-5"><a href="solution-proposal.html#cb83-5" aria-hidden="true"></a><span class="im">from</span> langchain.chains <span class="im">import</span> LLMChain</span>
<span id="cb83-6"><a href="solution-proposal.html#cb83-6" aria-hidden="true"></a></span>
<span id="cb83-7"><a href="solution-proposal.html#cb83-7" aria-hidden="true"></a><span class="co"># Define structured schema for tweet analysis</span></span>
<span id="cb83-8"><a href="solution-proposal.html#cb83-8" aria-hidden="true"></a><span class="kw">class</span> TweetAnalysis(BaseModel):</span>
<span id="cb83-9"><a href="solution-proposal.html#cb83-9" aria-hidden="true"></a>    language: <span class="bu">str</span> <span class="op">=</span> Field(..., description<span class="op">=</span><span class="st">&quot;Language of the tweet&quot;</span>)</span>
<span id="cb83-10"><a href="solution-proposal.html#cb83-10" aria-hidden="true"></a>    topic: <span class="bu">str</span> <span class="op">=</span> Field(..., description<span class="op">=</span><span class="st">&quot;Main topic of the tweet&quot;</span>)</span>
<span id="cb83-11"><a href="solution-proposal.html#cb83-11" aria-hidden="true"></a>    emotion: <span class="bu">str</span> <span class="op">=</span> Field(..., description<span class="op">=</span><span class="st">&quot;Dominant emotion (joy, anger, fear, sadness, neutral)&quot;</span>)</span>
<span id="cb83-12"><a href="solution-proposal.html#cb83-12" aria-hidden="true"></a></span>
<span id="cb83-13"><a href="solution-proposal.html#cb83-13" aria-hidden="true"></a><span class="co"># Create prompt template for analysis</span></span>
<span id="cb83-14"><a href="solution-proposal.html#cb83-14" aria-hidden="true"></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb83-15"><a href="solution-proposal.html#cb83-15" aria-hidden="true"></a>    (<span class="st">&quot;system&quot;</span>, <span class="st">&quot;Analyze the tweet and extract neutral information: language, topic, and dominant emotion.&quot;</span>),</span>
<span id="cb83-16"><a href="solution-proposal.html#cb83-16" aria-hidden="true"></a>    (<span class="st">&quot;human&quot;</span>, <span class="st">&quot;</span><span class="sc">{tweet}</span><span class="st">&quot;</span>)</span>
<span id="cb83-17"><a href="solution-proposal.html#cb83-17" aria-hidden="true"></a>])</span>
<span id="cb83-18"><a href="solution-proposal.html#cb83-18" aria-hidden="true"></a></span>
<span id="cb83-19"><a href="solution-proposal.html#cb83-19" aria-hidden="true"></a><span class="co"># Create structured extractor that returns Pydantic objects</span></span>
<span id="cb83-20"><a href="solution-proposal.html#cb83-20" aria-hidden="true"></a>extractor <span class="op">=</span> prompt <span class="op">|</span> client.with_structured_output(</span>
<span id="cb83-21"><a href="solution-proposal.html#cb83-21" aria-hidden="true"></a>    schema<span class="op">=</span>TweetAnalysis,</span>
<span id="cb83-22"><a href="solution-proposal.html#cb83-22" aria-hidden="true"></a>    include_raw<span class="op">=</span><span class="va">True</span></span>
<span id="cb83-23"><a href="solution-proposal.html#cb83-23" aria-hidden="true"></a>)</span>
<span id="cb83-24"><a href="solution-proposal.html#cb83-24" aria-hidden="true"></a></span>
<span id="cb83-25"><a href="solution-proposal.html#cb83-25" aria-hidden="true"></a><span class="co"># Function to analyze a single tweet</span></span>
<span id="cb83-26"><a href="solution-proposal.html#cb83-26" aria-hidden="true"></a><span class="kw">def</span> analyze_single_tweet(tweet_text):</span>
<span id="cb83-27"><a href="solution-proposal.html#cb83-27" aria-hidden="true"></a>    <span class="cf">return</span> extractor.invoke({<span class="st">&quot;tweet&quot;</span>: tweet_text})[<span class="st">&#39;parsed&#39;</span>]</span>
<span id="cb83-28"><a href="solution-proposal.html#cb83-28" aria-hidden="true"></a></span>
<span id="cb83-29"><a href="solution-proposal.html#cb83-29" aria-hidden="true"></a><span class="co"># Apply to sample DataFrame</span></span>
<span id="cb83-30"><a href="solution-proposal.html#cb83-30" aria-hidden="true"></a>sample_df <span class="op">=</span> df.sample(<span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>).copy()</span>
<span id="cb83-31"><a href="solution-proposal.html#cb83-31" aria-hidden="true"></a>sample_df[<span class="st">&quot;Analysis&quot;</span>] <span class="op">=</span> sample_df[<span class="st">&quot;OriginalTweet&quot;</span>].<span class="bu">apply</span>(analyze_single_tweet)</span>
<span id="cb83-32"><a href="solution-proposal.html#cb83-32" aria-hidden="true"></a></span>
<span id="cb83-33"><a href="solution-proposal.html#cb83-33" aria-hidden="true"></a><span class="co"># Extract individual columns from the Pydantic object</span></span>
<span id="cb83-34"><a href="solution-proposal.html#cb83-34" aria-hidden="true"></a>sample_df[<span class="st">&quot;Language&quot;</span>] <span class="op">=</span> sample_df[<span class="st">&quot;Analysis&quot;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.language)</span>
<span id="cb83-35"><a href="solution-proposal.html#cb83-35" aria-hidden="true"></a>sample_df[<span class="st">&quot;Topic&quot;</span>] <span class="op">=</span> sample_df[<span class="st">&quot;Analysis&quot;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.topic)</span>
<span id="cb83-36"><a href="solution-proposal.html#cb83-36" aria-hidden="true"></a>sample_df[<span class="st">&quot;Emotion&quot;</span>] <span class="op">=</span> sample_df[<span class="st">&quot;Analysis&quot;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.emotion)</span>
<span id="cb83-37"><a href="solution-proposal.html#cb83-37" aria-hidden="true"></a></span>
<span id="cb83-38"><a href="solution-proposal.html#cb83-38" aria-hidden="true"></a><span class="co"># View the results</span></span>
<span id="cb83-39"><a href="solution-proposal.html#cb83-39" aria-hidden="true"></a>sample_df[[<span class="st">&quot;OriginalTweet&quot;</span>, <span class="st">&quot;Language&quot;</span>, <span class="st">&quot;Topic&quot;</span>, <span class="st">&quot;Emotion&quot;</span>]].head()</span></code></pre></div>
</div>
</div>
<div id="question-3-chatbot-with-additional-information" class="section level3 hasAnchor" number="8.2.3">
<h3><span class="header-section-number">8.2.3</span> Question 3: Chatbot with Additional Information<a href="solution-proposal.html#question-3-chatbot-with-additional-information" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This question asks for a chatbot that can help find information online OR use RAG (Retrieval-Augmented Generation). We’ll show both approaches.</p>
<div id="option-a-web-search-chatbot" class="section level4 hasAnchor" number="8.2.3.1">
<h4><span class="header-section-number">8.2.3.1</span> Option A: Web Search Chatbot<a href="solution-proposal.html#option-a-web-search-chatbot" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb84"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="solution-proposal.html#cb84-1" aria-hidden="true"></a><span class="im">from</span> typing <span class="im">import</span> Annotated</span>
<span id="cb84-2"><a href="solution-proposal.html#cb84-2" aria-hidden="true"></a><span class="im">from</span> typing_extensions <span class="im">import</span> TypedDict</span>
<span id="cb84-3"><a href="solution-proposal.html#cb84-3" aria-hidden="true"></a><span class="im">from</span> langgraph.graph <span class="im">import</span> StateGraph, START, END</span>
<span id="cb84-4"><a href="solution-proposal.html#cb84-4" aria-hidden="true"></a><span class="im">from</span> langgraph.graph.message <span class="im">import</span> add_messages</span>
<span id="cb84-5"><a href="solution-proposal.html#cb84-5" aria-hidden="true"></a><span class="im">from</span> langgraph.prebuilt <span class="im">import</span> ToolNode, tools_condition</span>
<span id="cb84-6"><a href="solution-proposal.html#cb84-6" aria-hidden="true"></a><span class="im">from</span> langgraph.checkpoint.memory <span class="im">import</span> MemorySaver</span>
<span id="cb84-7"><a href="solution-proposal.html#cb84-7" aria-hidden="true"></a><span class="im">from</span> langchain_tavily <span class="im">import</span> TavilySearch</span>
<span id="cb84-8"><a href="solution-proposal.html#cb84-8" aria-hidden="true"></a></span>
<span id="cb84-9"><a href="solution-proposal.html#cb84-9" aria-hidden="true"></a><span class="co"># Define the state for the chatbot</span></span>
<span id="cb84-10"><a href="solution-proposal.html#cb84-10" aria-hidden="true"></a><span class="kw">class</span> State(TypedDict):</span>
<span id="cb84-11"><a href="solution-proposal.html#cb84-11" aria-hidden="true"></a>    messages: Annotated[<span class="bu">list</span>, add_messages]</span>
<span id="cb84-12"><a href="solution-proposal.html#cb84-12" aria-hidden="true"></a></span>
<span id="cb84-13"><a href="solution-proposal.html#cb84-13" aria-hidden="true"></a><span class="co"># Set up tools and LLM</span></span>
<span id="cb84-14"><a href="solution-proposal.html#cb84-14" aria-hidden="true"></a>tool <span class="op">=</span> TavilySearch(max_results<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb84-15"><a href="solution-proposal.html#cb84-15" aria-hidden="true"></a>tools <span class="op">=</span> [tool]</span>
<span id="cb84-16"><a href="solution-proposal.html#cb84-16" aria-hidden="true"></a>llm_with_tools <span class="op">=</span> client.bind_tools(tools)</span>
<span id="cb84-17"><a href="solution-proposal.html#cb84-17" aria-hidden="true"></a></span>
<span id="cb84-18"><a href="solution-proposal.html#cb84-18" aria-hidden="true"></a><span class="kw">def</span> chatbot(state: State):</span>
<span id="cb84-19"><a href="solution-proposal.html#cb84-19" aria-hidden="true"></a>    <span class="co">&quot;&quot;&quot;Main chatbot function that processes user input.&quot;&quot;&quot;</span></span>
<span id="cb84-20"><a href="solution-proposal.html#cb84-20" aria-hidden="true"></a>    <span class="cf">return</span> {<span class="st">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="st">&quot;messages&quot;</span>])]}</span>
<span id="cb84-21"><a href="solution-proposal.html#cb84-21" aria-hidden="true"></a></span>
<span id="cb84-22"><a href="solution-proposal.html#cb84-22" aria-hidden="true"></a><span class="co"># Build the graph</span></span>
<span id="cb84-23"><a href="solution-proposal.html#cb84-23" aria-hidden="true"></a>builder <span class="op">=</span> StateGraph(State)</span>
<span id="cb84-24"><a href="solution-proposal.html#cb84-24" aria-hidden="true"></a>builder.add_node(<span class="st">&quot;chatbot&quot;</span>, chatbot)</span>
<span id="cb84-25"><a href="solution-proposal.html#cb84-25" aria-hidden="true"></a></span>
<span id="cb84-26"><a href="solution-proposal.html#cb84-26" aria-hidden="true"></a>tool_node <span class="op">=</span> ToolNode(tools<span class="op">=</span>tools)</span>
<span id="cb84-27"><a href="solution-proposal.html#cb84-27" aria-hidden="true"></a>builder.add_node(<span class="st">&quot;tools&quot;</span>, tool_node)</span>
<span id="cb84-28"><a href="solution-proposal.html#cb84-28" aria-hidden="true"></a></span>
<span id="cb84-29"><a href="solution-proposal.html#cb84-29" aria-hidden="true"></a><span class="co"># Add conditional edges: model -&gt; tools if tool calls needed, else end</span></span>
<span id="cb84-30"><a href="solution-proposal.html#cb84-30" aria-hidden="true"></a>builder.add_conditional_edges(</span>
<span id="cb84-31"><a href="solution-proposal.html#cb84-31" aria-hidden="true"></a>    <span class="st">&quot;chatbot&quot;</span>,</span>
<span id="cb84-32"><a href="solution-proposal.html#cb84-32" aria-hidden="true"></a>    tools_condition,</span>
<span id="cb84-33"><a href="solution-proposal.html#cb84-33" aria-hidden="true"></a>    {</span>
<span id="cb84-34"><a href="solution-proposal.html#cb84-34" aria-hidden="true"></a>        <span class="st">&quot;tools&quot;</span>: <span class="st">&quot;tools&quot;</span>,</span>
<span id="cb84-35"><a href="solution-proposal.html#cb84-35" aria-hidden="true"></a>        <span class="st">&quot;__end__&quot;</span>: END,   <span class="co"># explicit path for &quot;no tools needed&quot;</span></span>
<span id="cb84-36"><a href="solution-proposal.html#cb84-36" aria-hidden="true"></a>    },</span>
<span id="cb84-37"><a href="solution-proposal.html#cb84-37" aria-hidden="true"></a>)</span>
<span id="cb84-38"><a href="solution-proposal.html#cb84-38" aria-hidden="true"></a></span>
<span id="cb84-39"><a href="solution-proposal.html#cb84-39" aria-hidden="true"></a><span class="co"># Tools loop back to model</span></span>
<span id="cb84-40"><a href="solution-proposal.html#cb84-40" aria-hidden="true"></a>builder.add_edge(<span class="st">&quot;tools&quot;</span>, <span class="st">&quot;chatbot&quot;</span>)</span>
<span id="cb84-41"><a href="solution-proposal.html#cb84-41" aria-hidden="true"></a>builder.add_edge(START, <span class="st">&quot;chatbot&quot;</span>)</span>
<span id="cb84-42"><a href="solution-proposal.html#cb84-42" aria-hidden="true"></a></span>
<span id="cb84-43"><a href="solution-proposal.html#cb84-43" aria-hidden="true"></a><span class="co"># Add memory for conversation persistence</span></span>
<span id="cb84-44"><a href="solution-proposal.html#cb84-44" aria-hidden="true"></a>memory <span class="op">=</span> MemorySaver()</span>
<span id="cb84-45"><a href="solution-proposal.html#cb84-45" aria-hidden="true"></a>graph <span class="op">=</span> builder.<span class="bu">compile</span>(checkpointer<span class="op">=</span>memory)</span>
<span id="cb84-46"><a href="solution-proposal.html#cb84-46" aria-hidden="true"></a></span>
<span id="cb84-47"><a href="solution-proposal.html#cb84-47" aria-hidden="true"></a><span class="co"># Function to run the chatbot</span></span>
<span id="cb84-48"><a href="solution-proposal.html#cb84-48" aria-hidden="true"></a><span class="kw">def</span> stream_graph_updates(user_input: <span class="bu">str</span>, thread_id: <span class="bu">str</span> <span class="op">=</span> <span class="st">&quot;default&quot;</span>):</span>
<span id="cb84-49"><a href="solution-proposal.html#cb84-49" aria-hidden="true"></a>    <span class="co">&quot;&quot;&quot;Stream updates from the chatbot graph.&quot;&quot;&quot;</span></span>
<span id="cb84-50"><a href="solution-proposal.html#cb84-50" aria-hidden="true"></a>    config <span class="op">=</span> {<span class="st">&quot;configurable&quot;</span>: {<span class="st">&quot;thread_id&quot;</span>: thread_id}}</span>
<span id="cb84-51"><a href="solution-proposal.html#cb84-51" aria-hidden="true"></a>    <span class="cf">for</span> event <span class="kw">in</span> graph.stream({<span class="st">&quot;messages&quot;</span>: [{<span class="st">&quot;role&quot;</span>: <span class="st">&quot;user&quot;</span>, <span class="st">&quot;content&quot;</span>: user_input}]}, config<span class="op">=</span>config):</span>
<span id="cb84-52"><a href="solution-proposal.html#cb84-52" aria-hidden="true"></a>        <span class="cf">for</span> value <span class="kw">in</span> event.values():</span>
<span id="cb84-53"><a href="solution-proposal.html#cb84-53" aria-hidden="true"></a>            <span class="bu">print</span>(<span class="st">&quot;Assistant:&quot;</span>, value[<span class="st">&quot;messages&quot;</span>][<span class="op">-</span><span class="dv">1</span>].content)</span>
<span id="cb84-54"><a href="solution-proposal.html#cb84-54" aria-hidden="true"></a></span>
<span id="cb84-55"><a href="solution-proposal.html#cb84-55" aria-hidden="true"></a><span class="co"># Interactive chatbot loop</span></span>
<span id="cb84-56"><a href="solution-proposal.html#cb84-56" aria-hidden="true"></a><span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb84-57"><a href="solution-proposal.html#cb84-57" aria-hidden="true"></a>    <span class="cf">try</span>:</span>
<span id="cb84-58"><a href="solution-proposal.html#cb84-58" aria-hidden="true"></a>        user_input <span class="op">=</span> <span class="bu">input</span>(<span class="st">&quot;User: &quot;</span>)</span>
<span id="cb84-59"><a href="solution-proposal.html#cb84-59" aria-hidden="true"></a>        <span class="cf">if</span> user_input.lower() <span class="kw">in</span> [<span class="st">&quot;quit&quot;</span>, <span class="st">&quot;exit&quot;</span>, <span class="st">&quot;q&quot;</span>]:</span>
<span id="cb84-60"><a href="solution-proposal.html#cb84-60" aria-hidden="true"></a>            <span class="bu">print</span>(<span class="st">&quot;Goodbye!&quot;</span>)</span>
<span id="cb84-61"><a href="solution-proposal.html#cb84-61" aria-hidden="true"></a>            <span class="cf">break</span></span>
<span id="cb84-62"><a href="solution-proposal.html#cb84-62" aria-hidden="true"></a>        stream_graph_updates(user_input)</span>
<span id="cb84-63"><a href="solution-proposal.html#cb84-63" aria-hidden="true"></a>    <span class="cf">except</span>:</span>
<span id="cb84-64"><a href="solution-proposal.html#cb84-64" aria-hidden="true"></a>        <span class="co"># fallback if input() is not available</span></span>
<span id="cb84-65"><a href="solution-proposal.html#cb84-65" aria-hidden="true"></a>        user_input <span class="op">=</span> <span class="st">&quot;What do you know about LangGraph?&quot;</span></span>
<span id="cb84-66"><a href="solution-proposal.html#cb84-66" aria-hidden="true"></a>        <span class="bu">print</span>(<span class="st">&quot;User: &quot;</span> <span class="op">+</span> user_input)</span>
<span id="cb84-67"><a href="solution-proposal.html#cb84-67" aria-hidden="true"></a>        stream_graph_updates(user_input)</span>
<span id="cb84-68"><a href="solution-proposal.html#cb84-68" aria-hidden="true"></a>        <span class="cf">break</span></span></code></pre></div>
</div>
<div id="option-b-rag-retrieval-augmented-generation-system" class="section level4 hasAnchor" number="8.2.3.2">
<h4><span class="header-section-number">8.2.3.2</span> Option B: RAG (Retrieval-Augmented Generation) System<a href="solution-proposal.html#option-b-rag-retrieval-augmented-generation-system" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb85"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="solution-proposal.html#cb85-1" aria-hidden="true"></a><span class="im">from</span> langchain_openai <span class="im">import</span> OpenAIEmbeddings, AzureChatOpenAI</span>
<span id="cb85-2"><a href="solution-proposal.html#cb85-2" aria-hidden="true"></a><span class="im">from</span> langchain_core.vectorstores <span class="im">import</span> InMemoryVectorStore</span>
<span id="cb85-3"><a href="solution-proposal.html#cb85-3" aria-hidden="true"></a><span class="im">from</span> langchain_text_splitters <span class="im">import</span> RecursiveCharacterTextSplitter</span>
<span id="cb85-4"><a href="solution-proposal.html#cb85-4" aria-hidden="true"></a><span class="im">from</span> langchain_community.document_loaders <span class="im">import</span> WebBaseLoader</span>
<span id="cb85-5"><a href="solution-proposal.html#cb85-5" aria-hidden="true"></a><span class="im">from</span> langgraph.graph <span class="im">import</span> START, StateGraph, END</span>
<span id="cb85-6"><a href="solution-proposal.html#cb85-6" aria-hidden="true"></a><span class="im">from</span> typing_extensions <span class="im">import</span> List, TypedDict</span>
<span id="cb85-7"><a href="solution-proposal.html#cb85-7" aria-hidden="true"></a><span class="im">from</span> langchain_core.documents <span class="im">import</span> Document</span>
<span id="cb85-8"><a href="solution-proposal.html#cb85-8" aria-hidden="true"></a><span class="im">import</span> bs4</span>
<span id="cb85-9"><a href="solution-proposal.html#cb85-9" aria-hidden="true"></a><span class="im">from</span> langchain <span class="im">import</span> hub</span>
<span id="cb85-10"><a href="solution-proposal.html#cb85-10" aria-hidden="true"></a></span>
<span id="cb85-11"><a href="solution-proposal.html#cb85-11" aria-hidden="true"></a><span class="co"># Set up embeddings and vector store</span></span>
<span id="cb85-12"><a href="solution-proposal.html#cb85-12" aria-hidden="true"></a>EMB_MODEL <span class="op">=</span> <span class="st">&quot;google/embeddinggemma-300m&quot;</span></span>
<span id="cb85-13"><a href="solution-proposal.html#cb85-13" aria-hidden="true"></a></span>
<span id="cb85-14"><a href="solution-proposal.html#cb85-14" aria-hidden="true"></a>embeddings <span class="op">=</span> HuggingFaceEmbeddings(</span>
<span id="cb85-15"><a href="solution-proposal.html#cb85-15" aria-hidden="true"></a>    model_name<span class="op">=</span>EMB_MODEL,</span>
<span id="cb85-16"><a href="solution-proposal.html#cb85-16" aria-hidden="true"></a>    model_kwargs<span class="op">=</span>{<span class="st">&quot;trust_remote_code&quot;</span>: <span class="va">True</span>},</span>
<span id="cb85-17"><a href="solution-proposal.html#cb85-17" aria-hidden="true"></a>    encode_kwargs<span class="op">=</span>{<span class="st">&quot;normalize_embeddings&quot;</span>: <span class="va">True</span>},</span>
<span id="cb85-18"><a href="solution-proposal.html#cb85-18" aria-hidden="true"></a>)</span>
<span id="cb85-19"><a href="solution-proposal.html#cb85-19" aria-hidden="true"></a></span>
<span id="cb85-20"><a href="solution-proposal.html#cb85-20" aria-hidden="true"></a>vector_store <span class="op">=</span> InMemoryVectorStore(embeddings)</span>
<span id="cb85-21"><a href="solution-proposal.html#cb85-21" aria-hidden="true"></a></span>
<span id="cb85-22"><a href="solution-proposal.html#cb85-22" aria-hidden="true"></a><span class="co"># Load and chunk documents from web sources</span></span>
<span id="cb85-23"><a href="solution-proposal.html#cb85-23" aria-hidden="true"></a>loader <span class="op">=</span> WebBaseLoader(</span>
<span id="cb85-24"><a href="solution-proposal.html#cb85-24" aria-hidden="true"></a>    web_paths<span class="op">=</span>(<span class="st">&quot;https://nhhs.no/nhhs-fra-a-til-a/&quot;</span>,<span class="st">&quot;https://nhhs.no/interessegrupper/&quot;</span>, <span class="st">&quot;https://www.dn.no/&quot;</span>),</span>
<span id="cb85-25"><a href="solution-proposal.html#cb85-25" aria-hidden="true"></a>    bs_kwargs<span class="op">=</span><span class="bu">dict</span>(</span>
<span id="cb85-26"><a href="solution-proposal.html#cb85-26" aria-hidden="true"></a>        parse_only<span class="op">=</span>bs4.SoupStrainer(</span>
<span id="cb85-27"><a href="solution-proposal.html#cb85-27" aria-hidden="true"></a>            class_<span class="op">=</span>(<span class="st">&quot;post-content&quot;</span>, <span class="st">&quot;post-title&quot;</span>, <span class="st">&quot;post-header&quot;</span>)</span>
<span id="cb85-28"><a href="solution-proposal.html#cb85-28" aria-hidden="true"></a>        )</span>
<span id="cb85-29"><a href="solution-proposal.html#cb85-29" aria-hidden="true"></a>    ),</span>
<span id="cb85-30"><a href="solution-proposal.html#cb85-30" aria-hidden="true"></a>)</span>
<span id="cb85-31"><a href="solution-proposal.html#cb85-31" aria-hidden="true"></a>docs <span class="op">=</span> loader.load()</span>
<span id="cb85-32"><a href="solution-proposal.html#cb85-32" aria-hidden="true"></a></span>
<span id="cb85-33"><a href="solution-proposal.html#cb85-33" aria-hidden="true"></a><span class="co"># Split documents into chunks for better retrieval</span></span>
<span id="cb85-34"><a href="solution-proposal.html#cb85-34" aria-hidden="true"></a>text_splitter <span class="op">=</span> RecursiveCharacterTextSplitter(chunk_size<span class="op">=</span><span class="dv">1000</span>, chunk_overlap<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb85-35"><a href="solution-proposal.html#cb85-35" aria-hidden="true"></a>all_splits <span class="op">=</span> text_splitter.split_documents(docs)</span>
<span id="cb85-36"><a href="solution-proposal.html#cb85-36" aria-hidden="true"></a></span>
<span id="cb85-37"><a href="solution-proposal.html#cb85-37" aria-hidden="true"></a><span class="co"># Index chunks in the vector store</span></span>
<span id="cb85-38"><a href="solution-proposal.html#cb85-38" aria-hidden="true"></a>_ <span class="op">=</span> vector_store.add_documents(documents<span class="op">=</span>all_splits)</span>
<span id="cb85-39"><a href="solution-proposal.html#cb85-39" aria-hidden="true"></a></span>
<span id="cb85-40"><a href="solution-proposal.html#cb85-40" aria-hidden="true"></a><span class="co"># Pull a pre-built RAG prompt template from LangChain Hub</span></span>
<span id="cb85-41"><a href="solution-proposal.html#cb85-41" aria-hidden="true"></a>prompt <span class="op">=</span> hub.pull(<span class="st">&quot;rlm/rag-prompt&quot;</span>)</span>
<span id="cb85-42"><a href="solution-proposal.html#cb85-42" aria-hidden="true"></a></span>
<span id="cb85-43"><a href="solution-proposal.html#cb85-43" aria-hidden="true"></a><span class="co"># Define RAG state</span></span>
<span id="cb85-44"><a href="solution-proposal.html#cb85-44" aria-hidden="true"></a><span class="kw">class</span> State(TypedDict):</span>
<span id="cb85-45"><a href="solution-proposal.html#cb85-45" aria-hidden="true"></a>    question: <span class="bu">str</span></span>
<span id="cb85-46"><a href="solution-proposal.html#cb85-46" aria-hidden="true"></a>    context: List[Document]</span>
<span id="cb85-47"><a href="solution-proposal.html#cb85-47" aria-hidden="true"></a>    answer: <span class="bu">str</span></span>
<span id="cb85-48"><a href="solution-proposal.html#cb85-48" aria-hidden="true"></a></span>
<span id="cb85-49"><a href="solution-proposal.html#cb85-49" aria-hidden="true"></a><span class="co"># Define RAG functions</span></span>
<span id="cb85-50"><a href="solution-proposal.html#cb85-50" aria-hidden="true"></a><span class="kw">def</span> retrieve(state: State):</span>
<span id="cb85-51"><a href="solution-proposal.html#cb85-51" aria-hidden="true"></a>    <span class="co">&quot;&quot;&quot;Retrieve relevant documents based on the question.&quot;&quot;&quot;</span></span>
<span id="cb85-52"><a href="solution-proposal.html#cb85-52" aria-hidden="true"></a>    retrieved_docs <span class="op">=</span> vector_store.similarity_search(state[<span class="st">&quot;question&quot;</span>])</span>
<span id="cb85-53"><a href="solution-proposal.html#cb85-53" aria-hidden="true"></a>    <span class="cf">return</span> {<span class="st">&quot;context&quot;</span>: retrieved_docs}</span>
<span id="cb85-54"><a href="solution-proposal.html#cb85-54" aria-hidden="true"></a></span>
<span id="cb85-55"><a href="solution-proposal.html#cb85-55" aria-hidden="true"></a><span class="kw">def</span> generate(state: State):</span>
<span id="cb85-56"><a href="solution-proposal.html#cb85-56" aria-hidden="true"></a>    <span class="co">&quot;&quot;&quot;Generate answer based on retrieved context.&quot;&quot;&quot;</span></span>
<span id="cb85-57"><a href="solution-proposal.html#cb85-57" aria-hidden="true"></a>    docs_content <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\n\n</span><span class="st">&quot;</span>.join(doc.page_content <span class="cf">for</span> doc <span class="kw">in</span> state[<span class="st">&quot;context&quot;</span>])</span>
<span id="cb85-58"><a href="solution-proposal.html#cb85-58" aria-hidden="true"></a>    messages <span class="op">=</span> prompt.invoke({<span class="st">&quot;question&quot;</span>: state[<span class="st">&quot;question&quot;</span>], <span class="st">&quot;context&quot;</span>: docs_content})</span>
<span id="cb85-59"><a href="solution-proposal.html#cb85-59" aria-hidden="true"></a>    response <span class="op">=</span> client.invoke(messages)</span>
<span id="cb85-60"><a href="solution-proposal.html#cb85-60" aria-hidden="true"></a>    <span class="cf">return</span> {<span class="st">&quot;answer&quot;</span>: response.content}</span>
<span id="cb85-61"><a href="solution-proposal.html#cb85-61" aria-hidden="true"></a></span>
<span id="cb85-62"><a href="solution-proposal.html#cb85-62" aria-hidden="true"></a><span class="co"># Build RAG graph</span></span>
<span id="cb85-63"><a href="solution-proposal.html#cb85-63" aria-hidden="true"></a>builder <span class="op">=</span> StateGraph(State)</span>
<span id="cb85-64"><a href="solution-proposal.html#cb85-64" aria-hidden="true"></a>builder.add_node(<span class="st">&quot;retrieve&quot;</span>, retrieve)</span>
<span id="cb85-65"><a href="solution-proposal.html#cb85-65" aria-hidden="true"></a>builder.add_node(<span class="st">&quot;generate&quot;</span>, generate)</span>
<span id="cb85-66"><a href="solution-proposal.html#cb85-66" aria-hidden="true"></a>builder.add_edge(START, <span class="st">&quot;retrieve&quot;</span>)</span>
<span id="cb85-67"><a href="solution-proposal.html#cb85-67" aria-hidden="true"></a>builder.add_edge(<span class="st">&quot;retrieve&quot;</span>, <span class="st">&quot;generate&quot;</span>)</span>
<span id="cb85-68"><a href="solution-proposal.html#cb85-68" aria-hidden="true"></a>builder.add_edge(<span class="st">&quot;generate&quot;</span>, END)</span>
<span id="cb85-69"><a href="solution-proposal.html#cb85-69" aria-hidden="true"></a>graph <span class="op">=</span> builder.<span class="bu">compile</span>()</span>
<span id="cb85-70"><a href="solution-proposal.html#cb85-70" aria-hidden="true"></a></span>
<span id="cb85-71"><a href="solution-proposal.html#cb85-71" aria-hidden="true"></a><span class="co"># Use RAG system</span></span>
<span id="cb85-72"><a href="solution-proposal.html#cb85-72" aria-hidden="true"></a>response <span class="op">=</span> graph.invoke({<span class="st">&quot;question&quot;</span>: <span class="st">&quot;What&#39;s &#39;ASAP&#39;? Answer in english.&quot;</span>})</span>
<span id="cb85-73"><a href="solution-proposal.html#cb85-73" aria-hidden="true"></a><span class="bu">print</span>(response[<span class="st">&quot;answer&quot;</span>])</span></code></pre></div>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="exercises.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="final-words.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-summary.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ai-llm-course.pdf", "ai-llm-course.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
